{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "![HI-TEC 2025](https://raw.githubusercontent.com/FSCJ-FacultyDev/HITEC2025/main/images/hitec2025-logo.png)\n",
        "## Secure Programming with Python\n",
        "![SECURE PROGRAMMING WITH PYTHON](https://raw.githubusercontent.com/FSCJ-FacultyDev/HITEC2025/main/images/workshop-head-image.png)\n"
      ],
      "metadata": {
        "id": "7QVDVd0juPDD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prof. Pamela Brauda and David Singletary\n",
        "### Florida State College at Jacksonville"
      ],
      "metadata": {
        "id": "Lksqo1v4u4IJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![PART1](https://raw.githubusercontent.com/FSCJ-FacultyDev/HITEC2025/main/images/p1-head.png)\n",
        "# Part 1. Introductory Topics\n",
        "0. Welcome and Workshop Overview\n",
        "1. Git and GitHub for Secure Version Control\n",
        "2. Jupyter Notebooks and Google Colab\n",
        "3. Secure Coding Basics"
      ],
      "metadata": {
        "id": "g5jTCh-jjVqU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Welcome\n",
        "\n",
        "Thank you for enrolling in our workshop. The material we are presenting consists of excerpts from a recent weeklong course we taught at the NITIC Summer Working Connections in Columbus, OH (here is the link to the full course: https://github.com/FSCJ-FacultyDev/SWC-Columbus-2025). This course drew from a variety of sources, including books, websites, and personal experience gained over eight years of teaching Python at Florida State College at Jacksonville (FSCJ). Some of this content is part of the curriculum in our A.S. in Computer Information Technology (https://www.fscj.edu/academics/programs/as/2153), our A.S. in Data Science Technology (https://www.fscj.edu/academics/programs/as/2157), our B.A.S. in Information Systems Technology (https://www.fscj.edu/academics/programs/bs/S301) which includes concentrations in application development and FinTech, and our non-credit (CWE) course offerings.\n",
        "\n",
        "We've included a notebook containing references, and we loosely cite these throughout the content (apologies in advance to the American Psychological Association and to any workshop attendees who are sticklers for proper source citations)."
      ],
      "metadata": {
        "id": "NS9Gypf3I0vu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Secure Version Control with Git and GitHub\n",
        "- Let's kick the workshop off by building from the ground up with secure version control using two de facto tools: Git and GitHub.\n",
        "  - These form the backbone of secure software development infrastructure by enabling collaboration, access control, traceability, and early vulnerability detection.\n",
        "- [Git](https://git-scm.com/) and [GitHub](https://github.com/) allow students to learn secure coding practices and conduct peer reviews. Together, these tools provide the following capabilities:\n",
        "  - Support collaboration among multiple contributors without conflicts.\n",
        "  - Enhance reproducibility by offering transparency in both development and research workflows.\n",
        "  - Enforce access control by restricting unauthorized modifications through protected branches.\n",
        "  - Encourage structured, versioned, and well-documented coding practices."
      ],
      "metadata": {
        "id": "EkF9QzeHj_wb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "![GitHub Classroom Overview](https://raw.githubusercontent.com/FSCJ-FacultyDev/HITEC2025/main/images/day1-gitlogo.png)\n",
        "![GitHub Classroom Overview](https://raw.githubusercontent.com/FSCJ-FacultyDev/HITEC2025/main/images/day1-ghlogo.png)\n",
        "\n",
        "- **Git** ensures code changes are tracked, managed, and reviewed systematically for security and accountability.\n",
        "  - Branching and merging allow teams to develop features and security patches separately before integrating them into the main codebase.\n",
        "  - Commit history and diffs provide visibility into changes, helping to identify and prevent security vulnerabilities.\n",
        "  - Rollback and recovery capabilities enable reverting to previous versions to mitigate security breaches or accidental changes.\n",
        "- **GitHub** provides cloud-based tools for managing repositories, enforcing security policies, and controlling access.\n",
        "  - Pull requests and code reviews ensure changes are reviewed by peers before merging, reducing the risk of introducing vulnerabilities.\n",
        "  - Security tools in GitHub (e.g., Dependabot, secret scanning, code scanning) help detect vulnerabilities in dependencies and source code.\n",
        "  - Access controls and compliance features, such as protected branches and role-based permissions, enforce secure coding practices and industry standards."
      ],
      "metadata": {
        "id": "_uzCo72UkIne"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GitHub Classroom\n",
        "\n",
        "![GitHub Classroom Overview](https://raw.githubusercontent.com/FSCJ-FacultyDev/HITEC2025/main/images/day1-ghclassroom.png)\n",
        "\n",
        "- We use GitHub Classroom extensively in many of our data science and software development courses to manage coding assignments, encourage collaboration, and teach real-world version control practices.\n",
        "- The platform allows instructors to automatically generate private repositories for each student or team, streamlining assignment distribution and submission.\n",
        "- It enables instructors to monitor student progress, provide in-line feedback through pull requests, and even automate testing and grading using GitHub Actions.\n",
        "- Students gain hands-on experience with industry-standard tools while reinforcing best practices in collaborative and secure software development.\n",
        "- See our [HITEC 2023 presentation (PDF)](https://github.com/FSCJ-FacultyDev/HITEC2025/raw/main/docs/GitHubClassroom-Instructor.pdf) for more information on setting up GitHub Classroom.\n",
        "\n"
      ],
      "metadata": {
        "id": "nU9ew7uThk3b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 🛠️ Hands-On: Set Up a Private GitHub Repo for a Python Project\n",
        "\n",
        "In this exercise, we will create a private GitHub repository for a simple Python project, define a dependency in `requirements.txt`, and write a basic Python script that uses that dependency.\n",
        "\n",
        "---\n",
        "\n",
        "### 1. Create a Private GitHub Repository\n",
        "\n",
        "a. Go to [https://github.com](https://github.com) and log in.  \n",
        "b. Click the **+** icon in the top-right corner and choose **New repository**.  \n",
        "c. Fill in:  \n",
        "   - Repository name: `python-demo-project` (or similar)\n",
        "   - Description (optional)  \n",
        "   \n",
        "d. Under **Visibility**, select **Private**.  \n",
        "e. (Optional) Check **\"Add a README file\"**.  \n",
        "f. Click **Create repository**.  \n",
        "\n",
        "---\n",
        "\n",
        "### 2. Add a Dependency File\n",
        "\n",
        "a. In your new repository, click **Add file** > **Create new file**.  \n",
        "b. Name the file **requirements.txt**  \n",
        "c. In the editor, add the following line:  \n",
        "\n",
        "    requests==2.31.0\n",
        "\n",
        "4. Press **Commit changes** and enter a commit message in the dialog (e.g., *Create requirements.txt*), and click **Commit changes**.\n",
        "\n",
        "---\n",
        "\n",
        "### 3. Add a Python Script\n",
        "\n",
        "a. In the repository, click **Add file** > **Create new file**.  \n",
        "b. Name the file **main.py**  \n",
        "c. Paste in the following code:  \n",
        "\n",
        "    import requests\n",
        "\n",
        "    response = requests.get(\"https://www.example.com\")\n",
        "    if response.status_code == 200:\n",
        "        print(\"Successfully reached example.com\")\n",
        "    else:\n",
        "        print(\"Request failed with status:\", response.status_code)\n",
        "\n",
        "\n",
        "4. Commit the file.\n",
        "\n"
      ],
      "metadata": {
        "id": "DcKM4Q4UnydM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multi-Factor Authentication\n",
        "- GitHub supports Multi-Factor Authentication (MFA) to enhance account security by requiring users to provide an additional verification factor beyond their password (Settings > Password and authentication)\n",
        "- MFA can be enabled via:\n",
        "  - Time-based one-time passwords (TOTP) generated by authenticator apps like Google Authenticator, Authy, or the GitHub mobile app\n",
        "  - Security keys that support FIDO2/WebAuthn\n",
        "  - SMS-based authentication (less recommended due to security concerns).\n",
        "- Once enabled, MFA is required during login and when performing sensitive actions, such as modifying account settings or accessing repositories with heightened security policies.\n",
        "- Additionally, GitHub allows organizations to enforce MFA for members, ensuring stronger protection for repositories and codebases."
      ],
      "metadata": {
        "id": "Yp4Vpe0ntqtL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Role-Based Access Control (RBAC)\n",
        "- RBAC is a security model that restricts system access based on predefined roles assigned to users, ensuring they have only the necessary permissions to perform their tasks.\n",
        "- Instead of granting individual permissions directly, RBAC assigns permissions to roles, which are then assigned to users, simplifying access management and reducing security risks.\n",
        "- Originally formalized by NIST, RBAC is widely used in enterprise environments, databases, operating systems, and cloud platforms to enforce least privilege and improve compliance with security policies.\n",
        "- It helps organizations efficiently manage user access, streamline administrative tasks, and minimize the risk of unauthorized actions\n",
        "- GitHub uses RBAC by assigning predefined roles (like Read, Write, Admin) at the repository, organization, and enterprise levels to control user access, enabling least-privilege permissions and scalable access management."
      ],
      "metadata": {
        "id": "X93y6Vl9fV16"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Student Repositories\n",
        "- Access control must be balanced with collaborative learning when using GitHub in a classroom environment.\n",
        "- The goal is to promote collaboration while maintaining the integrity of the repository and preventing accidental or unauthorized modifications.\n",
        "- Instructors can assign Read access to students who only need to view a repository, Write access for those contributing code without merging, and Maintain or Admin roles for team leads or advanced students managing repository settings.\n",
        "- Branch protection rules allows instructors to ensure students follow proper version control workflows, such as requiring pull requests and code reviews before merging.\n",
        "- GitHub Classroom allows use of private (template) repositories to generate private forkable repos for students to support academic integrity."
      ],
      "metadata": {
        "id": "oQCE0lLVfnDu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Branch Protection Rules\n",
        "- Branch protection rules in GitHub help enforce version control best practices by restricting direct changes to important branches. To set them up:\n",
        "  - In the repository on GitHub, click on the \"Settings\" tab.\n",
        "  - In the left sidebar, under \"Code and automation\", click \"Branches\".\n",
        "  - In the \"Branch protection rules\" section, click \"Add rule\".\n",
        "  - In the \"Branch name pattern\" field, enter the branch name you want to protect (e.g., main, develop, or use wildcards like feature/*).\n",
        "  - Select Protection Options. GitHub provides several protection rules you can enable:\n",
        "    - Require pull request reviews before merging: set a required number of approvals (e.g., at least one review). Block self-reviews to enforce team feedback.\n",
        "    - Require status checks to pass before merging: ensure automated tests (CI/CD) pass before merging. Select specific checks (e.g., Linting, Unit Tests, Build).\n",
        "    - Require commit signatures: enforce cryptographic signatures to verify commit authenticity.\n",
        "    - Restrict who can push to the branch: allow only instructors or specific team members to push directly.\n",
        "    - Require branches to be up to date before merging: prevent merging outdated branches to avoid conflicts\n",
        "    - Prevent branch deletion: stop accidental or malicious deletion of protected branches.\n",
        "  - Save the Rule\n",
        "    - Review the settings.\n",
        "    - Click \"Create\" to apply the protection rule."
      ],
      "metadata": {
        "id": "yFsTlDVcgzMm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Examples of Branch Protection Rules for GitHub Projects\n",
        "\n",
        "---\n",
        "\n",
        "#### 1. Require Pull Request Reviews Before Merging  \n",
        "*Prevents direct commits to the main branch and enforces a code review process.*\n",
        "\n",
        "**Example Rule:**\n",
        "- Require at least one approved review before merging.  \n",
        "- Prevent self-approval (someone else must review the changes).  \n",
        "- Dismiss stale approvals if new commits are added.\n",
        "\n",
        "---\n",
        "\n",
        "#### 2. Require Status Checks to Pass Before Merging  \n",
        "*Prevents merging unless automated tests (CI/CD pipelines) pass.*\n",
        "\n",
        "**Example Rule:**\n",
        "- Require GitHub Actions tests to pass before merging.  \n",
        "- Block merging if tests fail.\n",
        "\n",
        "---\n",
        "\n",
        "#### 3. Restrict Who Can Push to a Branch (intro courses)\n",
        " *Limits who can make direct changes to critical branches.*\n",
        "\n",
        "**Example Rule:**\n",
        "- Only instructors can push directly to main.  \n",
        "- Students must use feature branches and open pull requests.\n",
        "\n",
        "---\n",
        "\n",
        "#### 4. Prevent Deletion of Protected Branches  \n",
        "*Stops accidental or malicious deletion of important branches.*\n",
        "\n",
        "**Example Rule:**\n",
        "- Prevent deletion of the main and develop branches.\n"
      ],
      "metadata": {
        "id": "ncdP4a4wju7V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 🛠️ Hands-On: Explore Branch Protection Rules in a GitHub repo\n",
        "\n",
        "In this exercise, we will explore branch protection rules for our previous GitHub repository.\n",
        "\n",
        "---\n",
        "\n",
        "- Modifying these rules is a common practice in professional workflows.\n",
        "\n",
        "1. Go to your repository on GitHub.\n",
        "2. Click the Settings tab (you must have admin access to see this option).\n",
        "3. In the left sidebar, select Branches.\n",
        "4. Under Branch protection rules, click **Add classic branch protection rule**\n",
        "5. In Branch name pattern, type **main**\n",
        "6. Verify **Allow deletions** is *unchecked* — this prevents the branch from being deleted.\n",
        "7. Other rules you can set:\n",
        "  - Require a pull request before merging\n",
        "  - Require status checks (e.g. automation tool checks) to pass before merging\n",
        "8. Click Create or Save changes at the bottom.  \n",
        "(Disregard any warnings about non-enforcement of your rules due to use of a free account.)"
      ],
      "metadata": {
        "id": "K4YnTjnslGXC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Managing Sensitive Data (Secrets)\n",
        "## Never Commit Secrets!\n",
        "- API keys, credentials, and other sensitive data should never be committed to version control systems like Git because they can easily be exposed to unauthorized users, especially if the repository is public or shared across teams.\n",
        "- [Don't be like Dropbox!](https://blog.gitguardian.com/dropbox-breach-hack-github-circleci/)\n",
        "- Once exposed, these  values can be used by attackers to gain access to protected systems, steal data, abuse services (e.g., triggering rate limits or incurring unexpected costs), or compromise application security.\n",
        "- Even in private repositories, accidental leaks are possible through forks, backups, or misconfigured access controls.\n",
        "- Best practices dictate storing secrets in environment variables or secure vaults, and using .gitignore to exclude local configuration files that contain sensitive information."
      ],
      "metadata": {
        "id": "A--Rwr31vHDY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tools for Protecting Secrets\n",
        "- Tools like [git-secrets](https://github.com/awslabs/git-secrets) and [truffleHog](https://trufflesecurity.com/trufflehog) are designed to detect and prevent the accidental leakage of secrets—such as API keys, passwords, and tokens—into Git repositories.\n",
        "- These tools scan commit messages, staged files, and repository history for patterns that resemble sensitive information, helping developers catch issues before they are pushed to remote servers.\n",
        "-- **git-secrets** can be integrated as a pre-commit hook to block commits containing known secret patterns using regular expressions for detection.\n",
        "  - A common example of a known secret pattern is an AWS Access Key ID, e.g.,\n",
        "\n",
        "```\n",
        "          AKIAIOSFODNN7EXAMPLE\n",
        "```\n",
        "\n",
        "  - detected by the regex\n",
        "\n",
        "```\n",
        "          AKIA[0-9A-Z]{16}\n",
        "```\n",
        "\n",
        "- **truffleHog** performs deep scans for high-entropy (highly random) strings that may indicate keys or credentials.\n"
      ],
      "metadata": {
        "id": "xchPgCs-wrch"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Static Analysis and Dependency Scanning of Code \"at Rest\"\n",
        "- Static analysis and dependency scanning in Python are essential practices for identifying code issues and securing third-party packages early in the development cycle.\n",
        "- **Static analysis** analyzes code without executing it in order to detect potential errors, code smells (signs of poor design or maintainability issues), security vulnerabilities, and other issues.\n",
        "- Static analysis tools like [pylint](https://pypi.org/project/pylint/), [flake8](https://flake8.pycqa.org/en/latest/), and [bandit](https://bandit.readthedocs.io/) examine Python code without executing it, flagging syntax errors, code style violations, and potential security flaws such as use of unsafe functions or insecure imports.\n",
        "- **Dependency scanning** automatically identifies and evaluates third-party libraries used in a project to detect known security vulnerabilities, outdated packages, and other issues.\n",
        "- Dependency scanning tools like [pip-audit](https://pypi.org/project/pip-audit/), [safety](https://www.getsafety.com/cli), or GitHub's built-in [Dependabot](https://docs.github.com/en/code-security/dependabot) check  configured packages for known security vulnerabilities."
      ],
      "metadata": {
        "id": "Rpwi8fGw53zk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 🛠️ Hands-On: Set Up a Private GitHub Repo with Dependabot Dependency Scanning\n",
        "\n",
        "- **Dependabot** is a built-in GitHub feature that scans dependency files (like requirements.txt for Python or package.json for Node.js) and opens pull requests to update outdated or insecure packages.\n",
        "- It helps keep projects secure and up to date with minimal manual effort.\n",
        "- In this exercise we will configure Dependabot to automatically check our Python project's dependencies for updates and known security vulnerabilities.\n",
        "\n",
        "1. Go to your Python project's GitHub Repository\n",
        "\n",
        "2. Enable GitHub Security Features\n",
        "  - a.\tClick the Settings tab of the repository.\n",
        "  - b.\tIn the left sidebar, go to **Advanced Security**.\n",
        "  - d.\tConfirm the following are enabled (the default) and enable them if necessary:\n",
        "    - Dependency graph\n",
        "    - Dependabot alerts\n",
        "    - Dependabot security updates\n",
        "\n",
        "3. Add a Dependabot Configuration File\n",
        "  - a.\tReturn to the main repo page and create a YAML file named **.github/dependabot.yml** (YAML is a configuration language; we are using it here to tell Dependabot how and when to automatically check for and suggest updates to the project dependencies).\n",
        "  - c.\tPaste the following configuration for Python dependencies:\n",
        "\n",
        "```\n",
        "version: 2\n",
        "updates:\n",
        "  - package-ecosystem: \"pip\"\n",
        "    directory: \"/\"  # Location of requirements.txt\n",
        "    schedule:\n",
        "      interval: \"weekly\"\n",
        "```\n",
        "4. Commit the file\n",
        "\n",
        "5. Review Alerts and Pull Requests\n",
        "  - a.\tUnder “Security/Dependabot alerts”, review any detected vulnerabilities. If issues are found, Dependabot may automatically open pull requests to update affected packages.\n",
        "  - c.\tUnder “Insights/Dependency Graph/Dependabot”, review **Recent update jobs**.\n"
      ],
      "metadata": {
        "id": "VZlgd2-9oo5L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Jupyter Notebooks and Google Colab\n",
        "- Jupyter Notebooks and Google Colab provide flexible, interactive environments for secure coding practices, enabling developers to test and refine security-focused scripts in isolated, controlled settings.\n",
        "  - Support for Python and various security-related libraries, making them useful for tasks like penetration testing, secure coding education, and cryptographic implementations.\n",
        "  - Built-in execution controls, users can safely run code in segmented cells, reducing the risk of unintended operations.\n",
        "- Colab’s cloud-based execution adds an extra layer of security by sandboxing processes away from local machines, preventing potential malware execution.\n",
        "- Both platforms facilitate reproducibility and collaboration, allowing security teams to document vulnerabilities and share insights while maintaining strict access controls."
      ],
      "metadata": {
        "id": "0THCdXdmpuYi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Secure Coding Basics"
      ],
      "metadata": {
        "id": "S2jFs_f9xb11"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Coding Style\n",
        "- Good coding style is essential because it promotes clear, consistent, and readable code, making it easier to spot logic errors, unintended behavior, and security flaws during development and review."
      ],
      "metadata": {
        "id": "ur7m7M7SQj7l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GotoFail: A Case Study in Style-Related Vulnerabilities\n",
        "The **goto fail** bug was a critical security flaw in Apple’s SSL/TLS implementation (discovered in 2014)\n",
        "  - It was caused by a duplicate goto statement in the C code.\n",
        "  - The defect caused a certificate validation operation to prematurely exit, allowing attackers to impersonate secure websites and intercept encrypted communications.\n",
        "\n",
        "\n",
        "```\n",
        "// NOTE: This is C++, not Python\n",
        "if ((err = SSLHashSHA1.update(&hashCtx, &serverRandom)) != 0)\n",
        "    goto fail;\n",
        "if ((err = SSLHashSHA1.update(&hashCtx, &signedParams)) != 0)\n",
        "    goto fail;\n",
        "    goto fail;  // <- This accidental second 'goto fail;' is the bug\n",
        "if ((err = SSLHashSHA1.final(&hashCtx, &hashOut)) != 0)\n",
        "    goto fail;\n",
        "```\n"
      ],
      "metadata": {
        "id": "xkjJeSDFVoQX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PEP 8 and Python Style Guidelines\n",
        "\n",
        "- A Python Enhancement Proposal (PEP) describes a new feature, process, or  guideline for the Python community.\n",
        "  - PEPs provide a structured way to propose, discuss, and document changes to the language.\n",
        "    - PEP 1 (https://peps.python.org/pep-0001/) was written in March 2000 and defines what PEPs are for and how they should be used.\n",
        "    - PEPs 2–7 set guidelines for Python's development, including the PEP index and workflow (PEP 2), PEP guidelines for informational proposals (PEP 3), procedures for Python releases (PEP 4 and 6), deprecation policy (PEP 5), and how to submit patches (PEP 7).\n",
        "    - PEP 8 (https://peps.python.org/pep-0008/) provides Python coding style guidelines for maintainable code\n",
        "  - As instructors of introductory programming courses, we have the opportunity to teach the need for code style discipline and best practices early in a student's learning journey.\n",
        "  - By teaching established and consistent conventions we can help students develop habits that lead to more reliable and professional software.\n",
        "\n"
      ],
      "metadata": {
        "id": "n7i-LVxLhxw-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Guidelines\n",
        "\n",
        "- These guidelines emphasize code readability and foster a mindset that prioritizes security and maintainability—critical skills for aspiring developers.\n",
        "\n",
        "1. Formatting for Readability and Maintainability\n",
        "2. Naming Conventions\n",
        "3. Module Imports\n",
        "4. Documentation and Comments"
      ],
      "metadata": {
        "id": "IZO_qFlRjh5g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Formatting for Readability and Maintainability\n",
        "\n",
        "- Consistent Indentation (https://peps.python.org/pep-0008/#indentation)\n",
        "  - Use 4 spaces (not tabs) per indentation level to avoid confusion that could lead to logical errors.\n",
        "- Maximum Line Length (https://peps.python.org/pep-0008/#maximum-line-length)\n",
        "  - 79 characters prevents the need for horizontal scrolling, making it easier to audit code for security flaws.\n",
        "\n"
      ],
      "metadata": {
        "id": "cYTFIkbJU3xY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Naming Conventions\n",
        "- https://peps.python.org/pep-0008/#naming-conventions\n",
        "- Use meaningful names for variables, functions, and classes.\n",
        "- Avoid **shadowing**\n",
        "  - Shadowing occurs when a local variable or function name in your code overrides a built-in name, making the original built-in temporarily inaccessible.\n",
        "  - Don't use names that overwrite Python built-ins (e.g., don’t name a variable **id**, **list**, or **sum**).\n",
        "- Use CAPITALIZED_NAMES for constants that shouldn’t be modified."
      ],
      "metadata": {
        "id": "TurxyRhsVK3Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# shadowing and constants\n",
        "\n",
        "TAX_RATE = 0.07 # FL sales tax, won't change without legislation\n",
        "sum = 10  # Overwrites the built-in sum function\n",
        "\n",
        "numbers = [1, 2, 3]\n",
        "total = sum(numbers)\n",
        "\n",
        "del sum # fixes it, comment out previous line first\n",
        "total = sum(numbers)\n",
        "print(total)\n",
        "\n",
        "print(total + (1 + TAX_RATE))"
      ],
      "metadata": {
        "id": "NodtC3tEWi1o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Module Imports\n",
        "\n",
        "# 🛠️ Hands-On: Demonstrating Wildcard Import Issues\n",
        "- Avoid wildcard imports\n",
        "\n",
        "```\n",
        "    from module import *\n",
        "```\n",
        "\n",
        "- This can introduce unintended variables and functions into the namespace, leading to unpredictable behavior."
      ],
      "metadata": {
        "id": "WRGNyKqYXrTb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create two module files dynamically with conflicting function names\n",
        "\n",
        "# First module: math_tools with an add() function\n",
        "# that performs numerical addition\n",
        "with open('math_tools.py', 'w') as f:\n",
        "    f.write(\"\"\"\n",
        "def add(x, y):\n",
        "    return x + y\n",
        "\"\"\")\n",
        "\n",
        "# Second module: string_tools with an add() function\n",
        "# that performs string concatenation\n",
        "with open('string_tools.py', 'w') as f:\n",
        "    f.write(\"\"\"\n",
        "def add(x, y):\n",
        "    return x + \" \" + y\n",
        "\"\"\")\n",
        "\n",
        "# Import all contents from math_tools using wildcard import\n",
        "from math_tools import *\n",
        "print(\"Imported math_tools\")\n",
        "# Show memory address of the current add() function\n",
        "print(\"id(add) after math_tools import:\", id(add))\n",
        "\n",
        "# Import all contents from string_tools — this silently\n",
        "# overwrites the previous add()\n",
        "from string_tools import *\n",
        "print(\"Imported string_tools\")\n",
        " # Show memory address has change — function was overwritten\n",
        "print(\"id(add) after string_tools import:\", id(add))\n",
        "\n",
        "# Test which 'add' function is currently in scope\n",
        "# (hint: it's the one from string_tools).\n",
        "print(\"\\nTesting add(2, 3):\")\n",
        "try:\n",
        "    # Will raise a TypeError because string concatenation expects strings\n",
        "    result = add(2, 3)\n",
        "    print(\"Result of add(2, 3):\", result)\n",
        "except Exception as e:\n",
        "    # Catch error caused by conflicting function definitions\n",
        "    print(\"Error:\", e)\n",
        "\n",
        "# Clean up: delete dynamically created module files\n",
        "import os\n",
        "os.remove('math_tools.py')\n",
        "os.remove('string_tools.py')\n"
      ],
      "metadata": {
        "id": "mfJiv3RiYF0R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fix the problem shown in previous cell.\n",
        "# Import the modules explicitly using aliases to avoid conflicts\n",
        "import math_tools as mt\n",
        "import string_tools as st\n",
        "\n",
        "# Call add() from each module explicitly\n",
        "print(\"Calling math_tools.add(2, 3):\")\n",
        "try:\n",
        "    result_math = mt.add(2, 3)  # This performs numerical addition\n",
        "    print(\"Result:\", result_math)\n",
        "except Exception as e:\n",
        "    print(\"Error in math_tools.add:\", e)\n",
        "\n",
        "print(\"\\nCalling string_tools.add('hello', 'world'):\")\n",
        "try:\n",
        "    result_string = st.add(\"hello\", \"world\")  # This performs string concatenation\n",
        "    print(\"Result:\", result_string)\n",
        "except Exception as e:\n",
        "    print(\"Error in string_tools.add:\", e)"
      ],
      "metadata": {
        "id": "Oo3MNZ-57Dqw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Whitespace\n",
        "\n",
        "- https://peps.python.org/pep-0008/#whitespace-in-expressions-and-statements\n",
        "\n",
        "- Use spaces around operators and after commas to improve readability. Do this:\n",
        "\n",
        "```\n",
        "    x = a + b\n",
        "```\n",
        "\n",
        "- instead of this:\n",
        "\n",
        "```\n",
        "    x=a+b\n",
        "```\n",
        "\n",
        "- Avoid extraneous whitespace in expressions; instead of:\n",
        "\n",
        "```\n",
        "    x = (a + b ) # (trailing space inside parentheses)\n",
        "```\n",
        "\n",
        "- Do this:\n",
        "\n",
        "```\n",
        "    x = (a + b)\n",
        "```"
      ],
      "metadata": {
        "id": "mmtNsY-NyIcD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exception Handling\n",
        "- https://peps.python.org/pep-0008/#programming-recommendations\n",
        "- Don’t use \"bare except\" statements. Instead of:\n",
        "\n",
        "```\n",
        "    try:\n",
        "        process_data()\n",
        "    except:\n",
        "        pass # Silently ignores errors (including critical ones)\n",
        "```\n",
        "\n",
        "- Do this:\n",
        "\n",
        "```\n",
        "    try:\n",
        "        process_data()\n",
        "    except (ValueError, KeyError) as e:\n",
        "        logger.error(f\"Processing failed: {e}\")  # Log the issue\n",
        "```"
      ],
      "metadata": {
        "id": "1tfGjtb6y2Bw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Raise exceptions explicitly and use meaningful exception types with clear messages.  \n",
        "  Instead of:\n",
        "\n",
        "```\n",
        "    raise Exception(\"Error occurred\")  # Valid but non-specific\n",
        "```\n",
        "\n",
        "- Do this:\n",
        "\n",
        "```\n",
        "    raise ValueError(\"Invalid input\")\n",
        "```"
      ],
      "metadata": {
        "id": "qN6hZWxuzTx6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Documentation and Comments\n",
        "- https://peps.python.org/pep-0008/#comments\n",
        "- Use docstrings for function behavior and security emphasis"
      ],
      "metadata": {
        "id": "ZSKxmWY80geE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sanitize_input(user_input):\n",
        "    \"\"\"\n",
        "    Cleans user input to prevent injection attacks.\n",
        "\n",
        "    This function removes potentially dangerous characters\n",
        "    to protect against code injection vulnerabilities.\n",
        "\n",
        "    Args:\n",
        "        user_input (str): The input string provided by the user.\n",
        "\n",
        "    Returns:\n",
        "        str: A sanitized version of the input safe for further processing.\n",
        "    \"\"\"\n",
        "    return user_input.replace(\"<\", \"\").replace(\">\", \"\").replace(\";\", \"\")\n",
        "\n",
        "print(help(sanitize_input))\n"
      ],
      "metadata": {
        "id": "dTUvCEtZ02-r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Avoid inline comments disclosing security-sensitive information. Instead of:\n",
        "\n",
        "```\n",
        "\t# Hashing passwords with MD5 (insecure)\n",
        "```\n",
        "\n",
        "- Do this:\n",
        "\n",
        "```\n",
        "\t# Securely hash passwords\n",
        "```"
      ],
      "metadata": {
        "id": "kkLe9LZM05sl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loops, Lists, Tuples, and Dictionaries"
      ],
      "metadata": {
        "id": "z-l4lIGY06Y4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loops / Secure Iteration\n",
        "\n",
        "- Avoid Infinite Loops and Ensure Proper Termination\n",
        "- Infinite loops can cause a program to become unresponsive, consume excessive system resources, or create security vulnerabilities such as denial-of-service (DoS) risks.\n",
        "- To ensure proper termination of loops, follow these best practices"
      ],
      "metadata": {
        "id": "EXc_1OpK1C0F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use explicit loop conditions: ensure loops have well-defined termination conditions\n",
        "\n",
        "count = 0\n",
        "while count < 10:  # Proper termination condition\n",
        "    print(count)\n",
        "    count += 1  # Ensure progress towards termination"
      ],
      "metadata": {
        "id": "BcsB25ks1HKc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Avoid using while True without a break condition\n",
        "\n",
        "while True:\n",
        "    # processing steps ...\n",
        "    #\n",
        "    user_input = input(\"Enter 'exit' to stop: \")\n",
        "    if user_input.lower() == 'exit':\n",
        "        break"
      ],
      "metadata": {
        "id": "NCQwbKVf1Hyp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Implement Timeouts/Iteration Limits\n",
        "- When processing user input or external data, avoid infinite loops by implementing timeouts or iteration limits.\n",
        "\n",
        "  ```\n",
        "  import time\n",
        "\n",
        "  start_time = time.time()\n",
        "  timeout = 5  # seconds\n",
        "\n",
        "  while time.time() - start_time < timeout:\n",
        "      if some_condition():  # Replace with actual condition\n",
        "          break\n",
        "  ```"
      ],
      "metadata": {
        "id": "ktytXYxA7wEf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Instead of looping through large datasets, use generators to iterate over data securely and avoid excessive memory usage.\n",
        "- The **yield** operator allows a function to produce values one at a time, pausing execution between each value and resuming from the same point, making it ideal for use in generators."
      ],
      "metadata": {
        "id": "MWFOUqdtAG8g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The secure_generator function below produces one value at a time\n",
        "# instead of returning an entire list\n",
        "\n",
        "def secure_generator(n):\n",
        "    for i in range(n):\n",
        "        yield i  # Generates values on demand\n",
        "\n",
        "for value in secure_generator(10):\n",
        "    print(value)"
      ],
      "metadata": {
        "id": "eYOrS7if1O_7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Security Considerations for Lists and Tuples\n",
        "\n",
        "| List | Tuple |\n",
        "|------|-------|\n",
        "| Mutable | Immutable                  |\n",
        "| Dynamic collections | Fixed data structures |\n",
        "| Memory overhead for dynamic resizing | More memory efficient |\n",
        "| Built-in methods for modification | Fewer built-in methods |\n",
        "| Slightly slower for dynamic resizing | Sightly faster for large datasets |\n"
      ],
      "metadata": {
        "id": "P0MBAQs_1Sro"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tuples for Secure Data\n",
        "\n",
        "---\n",
        "- A **hash value** is a fixed-size numerical value produced by a **hash function**\n",
        "- A hash value uniquely represents the contents of an object and is used to quickly compare and retrieve objects in data structures like dictionaries and sets.\n",
        "- Tuples are **hashable** and can be used as dictionary keys or set elements as long as they only contain hashable elements.\n",
        "- Using tuples ensures that security-sensitive mappings (e.g., user permissions, access control lists) remain unchanged."
      ],
      "metadata": {
        "id": "XEHKvSCI1WrC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: Is an admin with read permissions allowed to perform a write?\n",
        "\n",
        "non_hashable_tuple = ([\"admin\", \"read\"], \"write\") # contains a list\n",
        "access_rights = { non_hashable_tuple: True }\n",
        "\n",
        "hashable_tuple = ((\"admin\", \"read\"), \"write\") # hashable\n",
        "access_rights = { hashable_tuple: True }"
      ],
      "metadata": {
        "id": "ocIOfPK_1Ze0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Copying Lists\n",
        "- Prevent unintended data modifications in lists by using tuples for data that should remain unchanged\n",
        "  - make copies of lists before passing them to functions if modification is not intended\n",
        "- Copying lists ensures that modifications to copied objects do not unintentionally affect the original, important when dealing with mutable and nested data structures\n",
        "- A Python list's copy method performs a shallow copy: it only copies the outer list and keeps references to mutable elements inside.\n",
        "- The **copy** module (https://docs.python.org/3/library/copy.html) allows programmers to create both shallow and deep copies of objects.\n",
        "  - The copy function in this module behaves similarly to the List's copy method.\n",
        "  - A **deep copy** creates a new compound object and recursively inserts copies into it of the objects found in the original.\n",
        "  - This is only relevant for compound objects (objects that contain other objects, like lists or class instances)."
      ],
      "metadata": {
        "id": "nSDqKum31aFy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Copying Lists: The Shallow Copy Problem\n",
        "- Since a shallow copy only copies references to the inner lists, modifying an element inside the copy also affects the original_list."
      ],
      "metadata": {
        "id": "9dFaqdr41hnu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "\n",
        "original_list = [[1, 2, 3], [4, 5, 6]]\n",
        "shallow_copy = copy.copy(original_list)\n",
        "\n",
        "# Modifying an inner list\n",
        "\n",
        "shallow_copy[0][0] = 99\n",
        "\n",
        "print(original_list)  # Output (modified): [[99, 2, 3], [4, 5, 6]]\n",
        "print(shallow_copy)   # Output (modified): [[99, 2, 3], [4, 5, 6]]"
      ],
      "metadata": {
        "id": "VVCqR3gi1l7V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 🛠️ Hands-On: Make a Deep Copy\n",
        "\n",
        "- copy.deepcopy() creates a new object and recursively copies all objects within it, ensuring that nested mutable objects are fully duplicated rather than just referenced so the copied object is completely independent."
      ],
      "metadata": {
        "id": "svlZD3bc1q-i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "\n",
        "original_list = [[1, 2, 3], [4, 5, 6]]\n",
        "deep_copy = copy.deepcopy(original_list)\n",
        "\n",
        "# Modifying an inner list\n",
        "deep_copy[0][0] = 99\n",
        "\n",
        "print(original_list)  # Output: [[1, 2, 3], [4, 5, 6]]  (Unchanged)\n",
        "print(deep_copy)      # Output: [[99, 2, 3], [4, 5, 6]]  (Modified)"
      ],
      "metadata": {
        "id": "07YKpxVZ1trX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Index Errors/Boundary Overflow Best Practices\n",
        "\n",
        "# 🛠️ Hands-On: Validating Index Values\n",
        "- Always check if an index is within range before accessing elements.\n",
        "- Use len() to determine valid index ranges.\n",
        "- Validate user input before using it as an index.\n"
      ],
      "metadata": {
        "id": "YcPrRoU31xO_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " # Safely retrieve an element from a list\n",
        " def get_element(lst, indx):\n",
        "    if not isinstance(indx, int): # Validate user input\n",
        "        print(\"Error: Index must be an integer.\")\n",
        "        return None\n",
        "    if 0 <= indx < len(lst):  # Check if index is in range\n",
        "        return lst[indx]\n",
        "    else:\n",
        "        print(\"Error: Index out of range.\")\n",
        "        return None\n",
        "\n",
        "# Example usage\n",
        "my_list = [\"apple\", \"banana\", \"cherry\"]\n",
        "# Valid index\n",
        "print(get_element(my_list, 1))\n",
        "# Out-of-range index\n",
        "print(get_element(my_list, 5))\n",
        "# Invalid input (not an integer)\n",
        "print(get_element(my_list, \"two\"))"
      ],
      "metadata": {
        "id": "CUQsTeTl10b8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 🛠️ Hands-On: Handling Unexpected Errors Using try-except.\n"
      ],
      "metadata": {
        "id": "VIxjtObSAlaf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# handle unexpected errors using try-except\n",
        "\n",
        "# return a default value or a meaningful message on failure.\n",
        "# log errors for debugging instead of silently failing.\n",
        "\n",
        "my_list = [10, 20, 30]\n",
        "try:\n",
        "    print(my_list[3])\n",
        "except IndexError:\n",
        "    print(\"Index out of range!\")"
      ],
      "metadata": {
        "id": "C3YJ8SLf13zA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# If You Must Use Indexes, Use Slicing\n",
        "  - Unlike direct indexing (e.g., my_list[3]), which could raise an IndexError if the index is out of bounds, slicing gracefully handles it.\n",
        "\n",
        "  # 🛠️ Hands-On: Using Slices"
      ],
      "metadata": {
        "id": "qI0EGT_86B1M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# uncomment for error example\n",
        "#my_list = [10, 20, 30]\n",
        "#print(my_list[5])  # IndexError: index out of range\n",
        "\n",
        "my_list = [10, 20, 30]\n",
        "print(my_list[:5])  # Prevents out-of-range errors"
      ],
      "metadata": {
        "id": "GmNuzYDr6Dbn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dictionaries\n",
        "## Use dict.get() for Dictionaries Instead of Direct Key Access\n",
        "- dict.get() for dictionary access is generally safer than direct key access (e.g., my_dict['key']) because it prevents potential KeyError exceptions that could disrupt program flow or unintentionally expose sensitive error messages.\n",
        "- A default return value can be specified when the key is missing, avoiding unhandled exceptions and reducing the likelihood of information leakage or crashes due to unexpected input or data manipulation by malicious users.\n",
        "- Gracefully handles edge cases.\n",
        "\n",
        "# 🛠️ Hands-On: Using dict.get() to Safely Access a Dictionary Element"
      ],
      "metadata": {
        "id": "Y8eNLesg3EL8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "user_data = {\n",
        "    \"username\": \"alice\",\n",
        "    \"email\": \"alice@example.com\"\n",
        "    # Note: 'phone' key is missing\n",
        "}\n",
        "\n",
        "# safe access using dict.get()\n",
        "phone = user_data.get(\"phone\", \"Not provided\")\n",
        "print(f\"Phone: {phone}\")\n",
        "\n",
        "# unsafe access using direct indexing (will raise KeyError)\n",
        "try:\n",
        "    phone_direct = user_data[\"phone\"]\n",
        "    print(f\"Phone (direct): {phone_direct}\")\n",
        "except KeyError:\n",
        "    print(\"Error: 'phone' key not found — unhandled exception avoided using .get()\")"
      ],
      "metadata": {
        "id": "MU02R3Ds3Gjt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# defaultdict for Missing Keys\n",
        "- **collections.defaultdict** is a built-in class which proactively handles missing dictionary keys without raising exceptions, enhancing code reliability and security.\n",
        "- Specifying a default factory function, such as int or list, automatically initializes missing keys with a safe, predictable value\n",
        "  - Prevents KeyError exceptions that might otherwise expose implementation details or crash the application due to unanticipated input.\n",
        "- In scenarios where input data is partially controlled by users, using defaultdict maintains program integrity, reduces error-handling complexity, and safeguards against logic flaws that could be exploited by attackers.\n",
        "\n",
        "# 🛠️ Hands-On: Using defaultdict() to Handle Missing Keys"
      ],
      "metadata": {
        "id": "nspf3gX13JbU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "# Initialize defaultdict with list as the default factory\n",
        "user_actions = defaultdict(list)\n",
        "\n",
        "# Simulated user input (some users may be missing from initial data)\n",
        "user_actions[\"alice\"].append(\"login\")\n",
        "user_actions[\"bob\"].append(\"upload_file\")\n",
        "user_actions[\"charlie\"].append(\"logout\")\n",
        "\n",
        "# Accessing a non-existent user — will NOT raise KeyError\n",
        "user_actions[\"david\"].append(\"download_report\")\n",
        "\n",
        "# Output all user actions\n",
        "for user, actions in user_actions.items():\n",
        "    print(f\"{user}: {actions}\")\n"
      ],
      "metadata": {
        "id": "ctKuO4fu3MYI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using Safer Data Structures\n",
        "- Use `collections.deque` when implementing fixed-size buffers.\n",
        "- Good for scenarios like rolling logs, recent event tracking, or sliding windows, where only the most recent items need to be retained.\n",
        "- Automatically removes oldest entries when the maximum size is reached, eliminating the need for manual cleanup logic.\n",
        "- Helps prevent unbounded memory growth in applications that process continuous or untrusted input streams, making it both efficient and safer.\n",
        "\n",
        "# 🛠️ Hands-On: Using a Deque"
      ],
      "metadata": {
        "id": "sDlAEl0P3fDw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import deque\n",
        "\n",
        "# Create a deque with a fixed max size of 3\n",
        "recent_inputs = deque(maxlen=3)\n",
        "\n",
        "# Simulated stream of user inputs\n",
        "inputs = [\"a\", \"b\", \"c\", \"d\", \"e\"]\n",
        "\n",
        "for item in inputs:\n",
        "    recent_inputs.append(item)\n",
        "    print(f\"Current buffer: {list(recent_inputs)}\")\n"
      ],
      "metadata": {
        "id": "EGUZnG3v3j97"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "![PART2](https://raw.githubusercontent.com/FSCJ-FacultyDev/HITEC2025/main/images/p2-head.png)\n",
        "# Part 2. Data Science and AI Topics"
      ],
      "metadata": {
        "id": "4l-JBLojMabf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Science Topics\n",
        "\n",
        "1. Input Validation and Sanitization\n",
        "\n",
        "2. Access Control and Data Privacy\n",
        "\n",
        "3. Secure Data Storage and Serialization\n",
        "\n",
        "4. Third-Party Library and Dependency Management"
      ],
      "metadata": {
        "id": "O_afjcKVh3DC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Input Validation and Sanitization\n",
        "- Ensure all data inputs (e.g., CSVs, JSON, user uploads) are validated before processing."
      ],
      "metadata": {
        "id": "GZb9t_h3mIva"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 🛠️ Hands-On: Clean Data with Pandas Built-in Methods\n",
        "- Use Pandas' built-in methods to check for missing values, unexpected types, or malformed rows.\n"
      ],
      "metadata": {
        "id": "XX7iadKxQ9LH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# input data\n",
        "data = {\n",
        "    \"name\": [\"Alice\", \"Bob\", None],\n",
        "    \"age\": [25, \"unknown\", 30],\n",
        "    \"email\": [\"alice@example.com\", \"bob[at]example.com\", \"carol@example.com\"]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Check for missing values\n",
        "if df.isnull().values.any():\n",
        "    print(\"Warning: Missing values detected!\")\n",
        "    print(df.isnull().sum())\n",
        "\n",
        "# Check for unexpected types (e.g., non-numeric ages)\n",
        "if not pd.api.types.is_numeric_dtype(df['age']):\n",
        "    print(\"Warning: Non-numeric values detected in 'age' column!\")\n",
        "    print(df['age'])\n",
        "\n",
        "# Sanitize: Attempt to coerce 'age' to numeric, mark errors\n",
        "df['age'] = pd.to_numeric(df['age'], errors='coerce')\n",
        "\n",
        "# Check for malformed email addresses (basic check)\n",
        "invalid_emails = df[~df['email'].str.contains(r\"^[^@]+@[^@]+\\.[^@]+$\", regex=True)]\n",
        "if not invalid_emails.empty:\n",
        "    print(\"Warning: Malformed email addresses found!\")\n",
        "    print(invalid_emails['email'])\n",
        "\n",
        "print(\"\\nCleaned DataFrame:\")\n",
        "print(df)\n"
      ],
      "metadata": {
        "id": "Wkmj4P1hmA1J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prevent Malicious Payloads\n",
        "\n",
        "- A code injection pattern is a sequence of input (e.g. Excel formulas or SQL statements) intended to insert malicious code into a program, aiming to trick the system into executing unintended commands, altering behavior, or compromising security."
      ],
      "metadata": {
        "id": "YSOXB56OmvII"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 🛠️ Hands-On: Sanitize Data\n",
        "- Use string prefix checks to sanitize potentially dangerous spreadsheet formulas in a DataFrame."
      ],
      "metadata": {
        "id": "fGWKaxQ7RM_H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# uploaded data\n",
        "data = {\n",
        "    \"username\": [\"alice\", \"bob\", \"=2+5\", \"+CMD|' /C calc'!A0\"],\n",
        "    \"comment\": [\"hello\", \"world\", \"=HYPERLINK('http://malicious.com')\", \"goodbye\"]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "print(\"Original data:\")\n",
        "print(df)\n",
        "\n",
        "# Sanitize dangerous formulas\n",
        "dangerous_prefixes = ('=', '+', '-', '@')\n",
        "\n",
        "def sanitize_formula(cell):\n",
        "    if isinstance(cell, str) and cell.startswith(dangerous_prefixes):\n",
        "        return \"'\" + cell\n",
        "    return cell\n",
        "\n",
        "# Apply sanitize_formula to each column separately\n",
        "df_sanitized = df.copy()\n",
        "for col in df_sanitized.columns:\n",
        "    # map() applies a function to each element in a column\n",
        "    df_sanitized[col] = df_sanitized[col].map(sanitize_formula)\n",
        "\n",
        "print(\"\\nSanitized data:\")\n",
        "print(df_sanitized)\n",
        "\n"
      ],
      "metadata": {
        "id": "xfTiWesZoLzK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Access Control and Data Privacy\n",
        "- Access control and data privacy come into play when  handling sensitive information, particularly in shared or multi-user environments.\n",
        "- One effective control strategy is to enforce access policies through **row and column filtering**, which ensures that users can only view or manipulate the data they are authorized to access (similar to creating a view in a database).\n",
        "- For example, an analyst might only be permitted to see records related to their assigned region (row-level filtering), or a customer support representative may be restricted from viewing personally identifiable information like social security numbers (column-level filtering)."
      ],
      "metadata": {
        "id": "VIFvSBiHgNoR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 🛠️ Hands-On: Use Column Filtering"
      ],
      "metadata": {
        "id": "peRPeuDSg5rI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Sample data\n",
        "df = pd.DataFrame({\n",
        "    'name': ['Alice', 'Bob', 'Carol'],\n",
        "    'email': ['alice@example.com', 'bob@example.com', 'carol@example.com'],\n",
        "    'ssn': ['123-45-6789', '987-65-4321', '555-55-5555'],\n",
        "    'salary': [70000, 80000, 75000]\n",
        "})\n",
        "\n",
        "print(\"Original DataFrame:\")\n",
        "print(df)\n",
        "\n",
        "# Only allow non-sensitive columns to be accessed\n",
        "df_filtered = df[['name', 'email']]\n",
        "\n",
        "print(\"\\nFiltered DataFrame (restricted access):\")\n",
        "print(df_filtered)"
      ],
      "metadata": {
        "id": "siazyb6gguvA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Anonymizing/Redacting Sensitive Fields\n",
        "- Anonymizing and redacting sensitive fields is a key data privacy technique used to protect personally identifiable information (PII) or confidential attributes within a dataset.\n",
        "- Anonymization typically involves transforming data so that individuals cannot be identified\n",
        "  - This can include name hashing or email address masking\n",
        "- Redaction replaces or removes sensitive values entirely (e.g., replacing a social security number with \"***-**-****\").\n",
        "- These methods are used when sharing data with third parties, performing analytics, or creating datasets for testing or training machine learning models."
      ],
      "metadata": {
        "id": "dxewUE5khAYb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 🛠️ Hands-On: Anonymize Sensitive Data in a Pandas DataFrame\n",
        "- This program demonstrates how to anonymize sensitive fields in a DataFrame using pandas.\n",
        "- It starts with a sample dataset containing personally identifiable information (PII) such as names, email addresses, and Social Security numbers.\n",
        "- A copy of the original DataFrame is created, and the sensitive columns (name, email, and ssn) are overwritten with the placeholder value \"REDACTED\".\n",
        "- This simple anonymization hides sensitive information while preserving the overall structure and non-sensitive data (like salary) for further analysis or sharing."
      ],
      "metadata": {
        "id": "g1jpP0eBf-gj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Sample data\n",
        "df = pd.DataFrame({\n",
        "    'name': ['Alice', 'Bob', 'Carol'],\n",
        "    'email': ['alice@example.com', 'bob@example.com', 'carol@example.com'],\n",
        "    'ssn': ['123-45-6789', '987-65-4321', '555-55-5555'],\n",
        "    'salary': [70000, 80000, 75000]\n",
        "})\n",
        "\n",
        "print(\"Original DataFrame:\")\n",
        "print(df)\n",
        "\n",
        "# Anonymize sensitive fields\n",
        "df_anonymized = df.copy()\n",
        "df_anonymized['name'] = 'REDACTED'\n",
        "df_anonymized['email'] = 'REDACTED'\n",
        "df_anonymized['ssn'] = 'REDACTED'\n",
        "\n",
        "print(\"\\nAnonymized DataFrame:\")\n",
        "print(df_anonymized)"
      ],
      "metadata": {
        "id": "EZTx6R5agzhq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Secure Data Storage and Serialization\n",
        "- Choosing safe serialization methods and securing the storage are critical parts of building secure applications.\n",
        "- The two processes are closely related because:\n",
        "- Serialization is the process of converting data into a format (like JSON, pickle, XML) so it can be saved to storage or transmitted over a network.\n",
        "- Secure data storage requires protecting the data both at rest (stored persistently and not actively being transmitted or processed) and during serialization to prevent unauthorized access, tampering, or exploitation.\n",
        "- If serialization is handled insecurely, attackers can\n",
        "  - Inject malicious payloads.\n",
        "  - Read sensitive data from poorly protected files.\n",
        "  - Exploit insecure formats (like untrusted pickle files) to execute arbitrary code.\n",
        "\n"
      ],
      "metadata": {
        "id": "Jt5GOtJp2sHc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Avoid pickle\n",
        "- pickle can execute arbitrary code when deserializing.\n",
        "- Never load pickle files from untrusted sources.\n",
        "\n",
        "```\n",
        "# Pickle is unsafe\n",
        "import pickle\n",
        "\n",
        "# Dangerous: loading untrusted data\n",
        "with open('user_data.pkl', 'rb') as f:\n",
        "    data = pickle.load(f)  # Vulnerable to code execution\n",
        "```\n"
      ],
      "metadata": {
        "id": "_Wp_QpaW3yd1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# JSON Serializes Securely\n",
        "- JSON is data-only — it cannot embed executable code.\n",
        "- It is better suited for secure storage and exchange of structured data.\n",
        "\n",
        "```\n",
        "# Using JSON for serialization\n",
        "import json\n",
        "\n",
        "# Safe: loading trusted JSON data\n",
        "with open('user_data.json', 'r') as f:\n",
        "    data = json.load(f)  # Parses data only, no code execution\n",
        "```"
      ],
      "metadata": {
        "id": "QmkgdamW4AYC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# But JSON is Text - How Can It Be Secured?\n",
        "- Sensitive data can be encrypted before writing it to storage.\n",
        "- Always validate and sanitize data when loading from any serialized format.\n",
        "- NOTE: Fernet encryption, provided by the cryptography library, is a Python-specific symmetric encryption method that securely encrypts data using a shared secret key. It is popular due to its simplicity, but is not suitable for large file encryption or streaming since it requires that the entire message reside in memory.\n",
        "- We describe various cryptography libraries in the Part 3 content."
      ],
      "metadata": {
        "id": "y8p0fKaX4bCE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 🛠️ Hands-On: Encrypt and Decrypt JSON Data\n",
        "- This program uses Fernet symmetric encryption to demonstrates secure encryption and decryption of JSON data.\n",
        "- It generates a key and saves it to a file, then creates a sample JSON object, serializes it to bytes, and encrypts it.\n",
        "- The encrypted data is then saved to a binary file.\n",
        "- The program then reads the key and encrypted data back from disk, validates that the encrypted file is not empty, and attempts to decrypt and parse the JSON securely.\n",
        "- If decryption fails due to tampering or corruption, it raises an InvalidToken error.\n",
        "- Finally, it prints the decrypted data and cleans up temporary files, ensuring confidentiality and integrity of the data at rest."
      ],
      "metadata": {
        "id": "eLaWecWjhOoL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from cryptography.fernet import Fernet, InvalidToken\n",
        "import json\n",
        "import os\n",
        "\n",
        "# generate and save the encryption key securely\n",
        "key = Fernet.generate_key()\n",
        "with open('secret.key', 'wb') as key_file:\n",
        "    key_file.write(key)\n",
        "\n",
        "# create a cipher using the key\n",
        "cipher = Fernet(key)\n",
        "\n",
        "# create JSON data to encrypt\n",
        "json_data = {\n",
        "    \"username\": \"admin\",\n",
        "    \"password\": \"SuperSecret123!\",\n",
        "    \"permissions\": [\"read\", \"write\", \"delete\"]\n",
        "}\n",
        "\n",
        "# serialize JSON to string and then encode to bytes\n",
        "json_string = json.dumps(json_data)\n",
        "data_bytes = json_string.encode('utf-8')\n",
        "\n",
        "# encrypt the serialized data\n",
        "encrypted_data = cipher.encrypt(data_bytes)\n",
        "\n",
        "# save the encrypted data to a file\n",
        "with open('secure_data.bin', 'wb') as data_file:\n",
        "    data_file.write(encrypted_data)\n",
        "\n",
        "# reload the key (yes, we already have it) and encrypt the data\n",
        "\n",
        "try:\n",
        "    # load the key\n",
        "    with open('secret.key', 'rb') as key_file:\n",
        "        loaded_key = key_file.read()\n",
        "\n",
        "    # recreate the cipher using the key\n",
        "    loaded_cipher = Fernet(loaded_key)\n",
        "\n",
        "    # load the encrypted data\n",
        "    with open('secure_data.bin', 'rb') as data_file:\n",
        "        encrypted_contents = data_file.read()\n",
        "\n",
        "    # validate - Check if the file is empty\n",
        "    if not encrypted_contents:\n",
        "        raise ValueError(\"Error: Encrypted file is empty.\")\n",
        "\n",
        "    # attempt decryption (sanitize - verify integrity)\n",
        "    decrypted_bytes = loaded_cipher.decrypt(encrypted_contents)\n",
        "\n",
        "    # decode bytes back to string and parse JSON\n",
        "    decrypted_json = json.loads(decrypted_bytes.decode('utf-8'))\n",
        "\n",
        "    # use the clean decrypted JSON data\n",
        "    print(\"Decrypted JSON data:\")\n",
        "    print(json.dumps(decrypted_json, indent=2))\n",
        "\n",
        "except InvalidToken:\n",
        "    print(\"Error: Decryption failed — data may have been tampered with!\")\n",
        "except Exception as e:\n",
        "    print(f\"Unexpected error: {e}\")\n",
        "\n",
        "# clean up files after demonstration\n",
        "os.remove('secure_data.bin')\n",
        "os.remove('secret.key')\n"
      ],
      "metadata": {
        "id": "eg0vFQ2P4ve2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Third-Party Library and Dependency Management"
      ],
      "metadata": {
        "id": "CggqPMEvIuEc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Third-Party Library and Dependency Management is a critical aspect of Python software development that ensures applications are built using reliable, secure, and maintainable external packages.\n",
        "  - Python's ecosystem boasts a vast array of third-party libraries available through the Python Package Index (PyPI), offering developers access to prebuilt functionality for tasks like web development, machine learning, data analysis, and cryptography.\n",
        "  - Relying on external packages introduces risks such as compatibility issues, deprecated APIs, or vulnerabilities.\n",
        "  - Proper dependency management practices help mitigate these risks and maintain the long-term health of a project.\n",
        "    - Keep dependencies up to date by patching known vulnerabilities.\n",
        "    - Use virtual environments or containers to isolate packages.\n",
        "    - Verify the integrity of libraries (e.g., via hash checks or using trusted sources like PyPI).\n",
        "- The most common tool for managing Python dependencies is pip, which allows developers to install packages using simple commands like *pip install requests*.\n",
        "- To ensure consistency across development environments, dependencies are often listed in a requirements.txt file. This file serves as a manifest of exact versions used in a project and can be regenerated using pip freeze > requirements.txt."
      ],
      "metadata": {
        "id": "V0pNC7QCln0X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the ! to run shell commands\n",
        "!pip install requests flask\n",
        "!pip freeze > requirements.txt"
      ],
      "metadata": {
        "id": "PRW1I3Flmc3b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "    - Example of a requirements.txt file:\n",
        "\n",
        "        flask==2.3.2  \n",
        "        requests==2.31.0  \n",
        "\n",
        "    - NOTE: Package sub-dependencies required by flask or requests will be downloaded and installed.\n",
        "\n"
      ],
      "metadata": {
        "id": "Qdso6vXkm1-8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Using virtual environments or containers like Docker ensures that dependencies are isolated, reproducible, and avoid polluting the global environment.\n",
        "  - Isolation enhances security by creating controlled, predictable environments and limiting exposure to global Python environments or system-wide packages.\n",
        "  - Reproducibility is especially important in teams or production deployments.\n",
        "  - Python developers frequently use tools like venv or virtualenv.\n",
        "  - These tools create project-specific environments where dependencies can be installed without conflicting with those of other projects.\n",
        "\n",
        "### The following is sample code only, it is not intended to be run in Colab\n",
        "  \n",
        "```\n",
        "# Create a virtual environment using the venv command\n",
        "# (the following code is intended to run on Linux)\n",
        "# Name the virtual environment venv -- to make sure it's confusing for beginners\n",
        "python -m venv venv\n",
        "\n",
        "# Activate the virtual environment\n",
        "source venv/bin/activate  # On Windows: venv\\Scripts\\activate\n",
        "\n",
        "# Install the specific packages required from the requirements.txt file\n",
        "pip install -r requirements.txt\n",
        "```  "
      ],
      "metadata": {
        "id": "KO0h4TQXoUuV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- For larger projects or those requiring more sophisticated workflows, tools like Poetry or Pipenv offer enhanced dependency resolution, semantic versioning, and lock file generation.\n",
        "  - These tools help manage both direct and transitive dependencies more precisely.\n",
        "  - Integrating security tools such as pip-audit or GitHub's Dependabot helps identify known vulnerabilities in third-party packages, enabling proactive patching.\n",
        "- The following code uses pip-audit to audit your project's dependencies:"
      ],
      "metadata": {
        "id": "cSQGUe6cpZeI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pip-audit\n",
        "!pip-audit\n",
        "\n",
        "# This demo is more effective using a command prompt or terminal on a local\n",
        "# machine vs.Colab; pip-audit in Colab will only audit the packages installed\n",
        "# in the current session, not your system environment or project virtualenv."
      ],
      "metadata": {
        "id": "tg9aK-CRpoUa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "  - Keeping data science libraries like NumPy and Pandas up to date is crucial:\n",
        "    - patching security vulnerabilities\n",
        "    - improving performance\n",
        "    - ensuring compatibility with other modern libraries.\n",
        "  - Outdated packages can expose applications to known security issues that are publicly documented in CVEs (Common Vulnerabilities and Exposures).\n",
        "  - Tools like pip list --outdated, pip-review, or automated scanners such as GitHub Dependabot can help identify outdated packages.\n"
      ],
      "metadata": {
        "id": "_JbCUeWsW24d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use pip to check for outdated packages\n",
        "!pip list --outdated"
      ],
      "metadata": {
        "id": "Bj8W-HxHYEdv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "  - Running the above code block may reveal some 'outdated' packages\n",
        "  - Sometimes the latest is not always the greatest\n",
        "    - The newest version of a package may not be compatible with other stable packages being used."
      ],
      "metadata": {
        "id": "eZ_xhv6xYjZp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Verifying the integrity of libraries helps ensure a malicious or tampered package is not installed.\n",
        "  - Python supports hash checking mode via pip, which uses SHA256 hashes in requirements.txt to verify the exact files being installed."
      ],
      "metadata": {
        "id": "PXK6zWyTpBSX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip download numpy==2.2.5\n",
        "!pip hash /content/numpy-2.2.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl"
      ],
      "metadata": {
        "id": "I0qTaDiWdz-6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- We can now add this information to our requirements.txt file:\n",
        "\n",
        "```\n",
        "numpy==2.2.5 \\\n",
        "  --hash=sha256:d84a1e9a5f2b4fadc3e9a2f8a69dfae9d048ba861b546f5e4f3a4a0b7a65c208\n",
        "```\n",
        "\n",
        "- Including a --hash with each dependency ensures the exact package file is used.\n",
        "- If someone uploads a malicious version of numpy==2.2.5 to PyPI, or if a mirror is compromised, pip will refuse to install it if the file’s SHA256 hash doesn’t match.\n",
        "- This protects development and deployment pipelines from executing compromised code during automated builds or deployments."
      ],
      "metadata": {
        "id": "6v_6vRPuOB_C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Best Practices\n",
        "By following best practices in dependency management such as pinning versions, isolating environments, regularly auditing packages, and avoiding unmaintained libraries, developers can reduce technical debt and enhance the reliability and security of Python applications."
      ],
      "metadata": {
        "id": "Z5MQvyl2qTeV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NOTE from \"Alice and Bob Learn Secure Coding\":\n",
        "[2] Janca, Ch. 6\n",
        "\"You might have noticed that I suggested Pip Freeze and then said not to pin your libraries. How can you both freeze and keep updating libraries? Whenever you have a chance to do a code update, you want to update as many libraries as you can, to avoid technical debt. If you have the libraries pinned, they won't do that. But when you move from environment to environment (dev ‐> QA ‐> staging), you do not want versions of your code changing, as your testing will be inaccurate. Once you are ready to go beyond dev, you freeze, but before that, you update, update, update (especially libraries!).\""
      ],
      "metadata": {
        "id": "g3XmgZe1oAlA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# AI Topics\n",
        "1. Using AI Safely and Securely\n",
        "2. Ethical Use of AI\n",
        "3. Data Integrity\n",
        "4. Defending Against Adversarial Attacks"
      ],
      "metadata": {
        "id": "fmcfpMyRqIrg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Using Artificial Intelligence Safely and Securely\n",
        "\n",
        "- As artificial intelligence becomes increasingly integrated into software development workflows, developers must focus on safety and security.\n",
        "  - [**Safety**](https://arxiv.org/pdf/1606.06565) protects the system and its users from unintentional harm.\n",
        "  - This includes preventing software bugs, ensuring system reliability, avoiding accidents (e.g., crashing an autonomous system), and mitigating unintended consequences of AI behavior.\n",
        "  - Safety is about making sure the system does what it's supposed to do, and doesn’t do something dangerous by mistake.\n",
        "  - [**Security**](https://arxiv.org/pdf/1802.07228) focuses on protecting the system from intentional harm, such as malicious attacks, unauthorized access, data breaches, or exploitation of vulnerabilities.\n",
        "  - It's about defending against external threats and ensuring confidentiality, integrity, and availability.\n",
        "- Tools such as code assistants, vulnerability scanners, and automated reasoning engines can help identify bugs, enforce secure coding standards, and streamline threat modeling.\n",
        "- Use caution when relying on AI-generated code, as it may introduce vulnerabilities or insecure results from training data."
      ],
      "metadata": {
        "id": "QN8lXnoViQ99"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Useful Tips from Alice and Bob\n",
        "[2] Ch. 15\n",
        "\n",
        "- Use AI to write user stories, documentation, and anything else that is written for your job.\n",
        "  - Double‐check everything before showing it to anyone else; the first draft will likely be imperfect.\n",
        "- Use AI to help you write code; just make sure you check it first and don't give it sensitive data when asking for that help.\n",
        "- Use AI to help you find vulnerabilities; if you can share your code (e.g., open source), ask it to find vulnerabilities.\n",
        "  - It might not be as good as a SAST tool, but if you have an AI and you don't have a SAST tool, take what you can get.\n",
        "- Ask AI to do threat models for you; you will likely come up with lots of ridiculous ideas, but it usually has one or two good ones.\n",
        "- Ask AI for help with design, describe what you want, and see what it comes up with.\n",
        "  - This is like asking a junior employee: the ideas can be a bit wacky, but you get a lot of results really fast, and some of it is usable.\n",
        "- Ask AI to add comments to your code.\n",
        "  - It might be able to add more than you would have the patience for.\n",
        "  - Be sure they are kept concise and brief; no one wants to read a novel.\n",
        "- Ask AI to suggest bug fixes; some of them will be good."
      ],
      "metadata": {
        "id": "fxbx9IZOYjVI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Caveats:\n",
        "- Do not allow AI to make decisions on behalf of applications without oversight\n",
        "  - Each decision should have some other part of the code not controlled by the AI validate the decision\n",
        "  - AI should never be trusted to make an important decision on its own\n",
        "- An AI should not be able to control itself or others\n",
        "  - Many current researchers cannot fully explain how models work or why they hallucinate\n",
        "- Do not share sensitive or private information with an AI unless you own or control it\n",
        "- Always fully review AI-generated code\n",
        "  - Don't use it if you don't understand how it works\n",
        "  - [Junior developers sometimes rely too heavily on them without fully understanding the code being created](https://www.calcalistech.com/ctechnews/article/ybba8gx5n)\n",
        "  - [As a junior developer, it’s important to learn the fundamentals](https://noncodersuccess.medium.com/should-junior-developers-use-ai-for-coding-24cc03717525)\n",
        "- Verify AI-generated content has not broken copyright\n",
        "  - Be sure it is original, properly attributed, and not derived from protected material."
      ],
      "metadata": {
        "id": "k1D_BSen9iMC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Ethical Use of AI\n",
        "## How Does AI Ethics Relate to Secure Development?\n",
        "1. Bias as a Security Risk\n",
        "\t- Biased models can lead to unfair treatment (e.g., in hiring or lending).\n",
        "\t- Security tie-in: Attackers can exploit known biases to game or manipulate models (e.g., feeding crafted inputs to skew recommendations).\n",
        "2. Data Privacy and Confidentiality\n",
        "\t- Users have a right to privacy; exposing sensitive data violates ethical standards.\n",
        "\t- Security tie-in: Poor privacy protections can lead to data leaks or model inversion attacks that reconstruct private training data.\n",
        "3. Accountability and Transparency\n",
        "\t- Users should know how decisions are made and be able to challenge them.\n",
        "\t- Security tie-in: Transparent systems allow for better auditing, threat detection, and accountability for model behavior and access.\n",
        "4. Adversarial Robustness as Ethical Responsibility\n",
        "\t- Systems should behave reliably and safely, especially in critical domains like healthcare or autonomous driving.\n",
        "\t- Security tie-in: Building defenses against adversarial attacks ensures models cannot be tricked into unsafe or harmful outputs.\n",
        "5. Fair Access and System Abuse\n",
        "\t- AI systems should not reinforce inequality or exclusion.\n",
        "\t- Security tie-in: Rate limiting, authentication, and abuse detection protect systems from being exploited for unfair advantage."
      ],
      "metadata": {
        "id": "vHHorBefrxTm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Compliance with Legal and Regulatory Requirements\n",
        "- Compliance guidelines such as the General Data Protection Regulation (GDPR) and U.S. Equal Employment Opportunity Commission (EEOC) is essential.\n",
        "- These regulations mandate responsible data handling, privacy protections, and fairness in areas like automated decision-making, user profiling, and employment screening.\n",
        "- Developers must ensure that AI-driven applications are transparent, auditable, and designed to avoid bias or discrimination\n",
        "- Robust security is required to protect sensitive data.\n",
        "- Proper data validation, encryption, access control, and audit logging play a critical role."
      ],
      "metadata": {
        "id": "hzPGtdBsnV0R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "5. Secure Model Deployment\n",
        "- Restrict access to inference endpoints and model files.\n",
        "\t- Authenticate and authorize API requests to prevent abuse or reverse engineering.\n",
        "\t- Protect models in memory and at rest using encryption and secure containers.\n",
        "6. Privacy-Preserving Machine Learning\n",
        "- Implement techniques like differential privacy, federated learning, or homomorphic encryption.\n",
        "\t- Mask or anonymize sensitive features during preprocessing.\n",
        "\t- Ensure compliance with data minimization principles.\n",
        "7. Monitoring and Incident Response\n",
        "- Continuously monitor model behavior for drift, misuse, or attacks.\n",
        "\t- Set up logging and alerting systems for unexpected input/output patterns.\n",
        "\t- Have a rollback or patching process in place for compromised models."
      ],
      "metadata": {
        "id": "8WVl-ifdrOUI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Data Integrity\n",
        "\n",
        "- Maintaining data integrity is fundamental to the development of secure and reliable AI systems, beginning with validating and cleaning training data to detect anomalies, outliers, or potentially malicious inserts that could impact model behavior or introduce vulnerabilities.\n",
        "- In traditional software development, we only need to focus on testing and versioning code. [6] Ch. 1  \n",
        "- In machine learning, we have to test and version our data as well\n",
        "- Indiscriminately accepting all available data might hurt your model’s performance and even make it susceptible to data poisoning attacks\n",
        "- High-quality, trusted data input is essential to reduce the risk.\n",
        "- Basic strategies for regularly auditing models for signs of weak performance can help, as well as using advanced measures such as [defensive distillation](https://arxiv.org/pdf/1511.04508) and [feature squeezing](https://arxiv.org/pdf/1704.01155).\n",
        "- [Cisco: How to detect and mitigate AI data poisoning](https://outshift.cisco.com/blog/ai-data-poisoning-detect-mitigate)\n",
        "- Implementing data versioning and **provenance tracking** (keeping a record of data origin, changes, and history) allows developers to trace the origin, transformations, and usage of datasets over time.\n",
        "- MLOps frameworks like [DVC (Data Version Control)](https://dvc.org/doc) provide built-in support for versioning and provenance tracking.\n",
        "- Reproducibility, accountability, and rollback are essential to handle potential contamination or error.\n",
        "- Data validation libraries, logging pipelines, and checksum verification help enforce these safeguards."
      ],
      "metadata": {
        "id": "wQxEequQod-c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 🛠️ Hands-On: Detect Model Poisoning Using IsolationForest\n",
        "- Detecting outliers using Scikit-Learn's IsolationForest algorithm can flag potentially poisoned samples during preprocessing.\n",
        "- IsolationForest detects outliers by repeatedly splitting data to see which points are easiest to isolate.\n",
        "- IsolationForest.fit_predict() labels each data point as either:\n",
        "  - 1 → inlier (normal)\n",
        "  - -1 → outlier (anomalous / possible poisoned sample)\n",
        "\n",
        "![IsolationForest](https://raw.githubusercontent.com/FSCJ-FacultyDev/HITEC2025/main/images/day2-isolationforest.png)"
      ],
      "metadata": {
        "id": "5LWwJlpcrlkj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import IsolationForest\n",
        "\n",
        "# Simulate training data with potential poisoned samples\n",
        "np.random.seed(42)\n",
        "\n",
        "# Generate 100 data points with 2 features from a normal distribution\n",
        "#   ~68% within ±1 standard deviation (i.e., between −1 and 1)\n",
        "#   ~95% within ±2 standard deviations (i.e., between −2 and 2)\n",
        "#   ~99.7% within ±3 standard deviations (i.e., between −3 and 3)\n",
        "normal_data = np.random.normal(loc=0.0, scale=1.0, size=(100, 2))\n",
        "\n",
        "# Manually create 2 outliers to simulate poisoned samples\n",
        "poisoned_data = np.array([[10, 10], [15, -12]])  # Simulated poisoned outliers\n",
        "\n",
        "# Stack the normal and poisoned data vertically to form one dataset\n",
        "data = np.vstack((normal_data, poisoned_data))\n",
        "\n",
        "# Convert to DataFrame for inspection\n",
        "df = pd.DataFrame(data, columns=[\"feature1\", \"feature2\"])\n",
        "\n",
        "# Apply Isolation Forest to detect outliers\n",
        "# (relative to this specific dataset)\n",
        "model = IsolationForest(contamination=0.05)\n",
        "df['anomaly'] = model.fit_predict(df[[\"feature1\", \"feature2\"]])\n",
        "\n",
        "# -1 indicates an outlier (possible poisoned sample)\n",
        "outliers = df[df['anomaly'] == -1]\n",
        "clean_data = df[df['anomaly'] == 1]\n",
        "\n",
        "print(\"Detected Outliers (Possible Poisoned Samples):\")\n",
        "print(outliers)"
      ],
      "metadata": {
        "id": "PJyNJuTUriaM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Defending Against Adversarial Attacks\n",
        "- **Adversarial attacks** involve subtly modified inputs designed to fool machine learning models into making incorrect predictions.\n",
        "- These are often imperceptible to humans but can drastically alter model outputs, revealing vulnerabilities in both the model and the broader software systems that depend on its predictions.\n",
        "- **Adversarial training** is a widely adopted technique which involves augmenting the training dataset with adversarial examples so that the model learns to classify both normal and adversarial inputs correctly.\n",
        "  - This helps prepare the model for real-world attacks by simulating them during training.\n",
        "- **Input regularization techniques**, such as adding noise or using dropout, further harden models by discouraging overfitting and encouraging the model to generalize better, reducing its sensitivity to small variations.\n",
        "- Detection mechanisms can also be used at inference time to identify and reject potentially adversarial inputs.\n",
        "  - These might involve monitoring for abnormal activation patterns (i.e., inputs that trigger unexpected neuron activation responses) or statistical flags that suggest input manipulation.\n",
        "- Evaluating model robustness can be performed using specialized testing frameworks like [CleverHans](https://cleverhans.io/) and [Foolbox](https://foolbox.readthedocs.io/en/stable/#) which generate adversarial examples and assess model susceptibility.\n",
        "- These tools support continuous security testing practices similar to **fuzzing** (feeding a program  large volumes of unexpected or random data to discover  vulnerabilities, crashes, or unexpected behavior) and penetration testing in traditional software."
      ],
      "metadata": {
        "id": "n_6HMq8J8hUk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 🛠️ Hands-On: Add Noise to Training Data"
      ],
      "metadata": {
        "id": "22PJiKG3ubfJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# adding noise for input regularization\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# Original input (e.g., a vector representing an image or features)\n",
        "original_input = np.array([0.5, 0.7, 0.2, 0.9])\n",
        "\n",
        "# Add Gaussian noise with mean 0 and standard deviation 0.1\n",
        "noise = np.random.normal(loc=0.0, scale=0.1, size=original_input.shape)\n",
        "noisy_input = original_input + noise\n",
        "\n",
        "print(\"Original input:\", original_input)\n",
        "print(\"Noisy input:   \", noisy_input)"
      ],
      "metadata": {
        "id": "PruuEkJGEe5l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Deep learning example: apply Gaussian noise during training for robustness\n",
        "\n",
        "import numpy as np\n",
        "from tensorflow.keras.layers import Input, Dense, GaussianNoise\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# Define the input layer with 4 features\n",
        "inputs = Input(shape=(4,))\n",
        "\n",
        "# Apply Gaussian noise (stddev = 0.1) to the input during training\n",
        "# Regularizes the model by making it less sensitive to small input changes\n",
        "x = GaussianNoise(0.1)(inputs)\n",
        "\n",
        "# Add a hidden dense layer with 16 neurons and ReLU activation\n",
        "x = Dense(16, activation='relu')(x)\n",
        "\n",
        "# Output layer with 1 neuron and sigmoid activation\n",
        "# (suitable for binary classification)\n",
        "outputs = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "# Build the model\n",
        "model = Model(inputs, outputs)\n",
        "\n",
        "# Compile the model with Adam optimizer and binary crossentropy loss function\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "\n",
        "# Sample batch of input data (3 samples with 4 features each)\n",
        "sample_input = np.array([\n",
        "    [0.5, 0.7, 0.2, 0.9],\n",
        "    [0.1, 0.3, 0.5, 0.2],\n",
        "    [0.9, 0.8, 0.1, 0.4]\n",
        "])\n",
        "\n",
        "# Perform a forward pass in training mode (noise is applied)\n",
        "predictions_with_noise = model(sample_input, training=True)\n",
        "\n",
        "# Perform a forward pass in inference mode (no noise applied)\n",
        "predictions_without_noise = model(sample_input, training=False)\n",
        "\n",
        "# Compare model predictions with and without input noise\n",
        "print(\"Predictions with noise:\\n\", predictions_with_noise.numpy())\n",
        "print(\"\\nPredictions without noise:\\n\", predictions_without_noise.numpy())"
      ],
      "metadata": {
        "id": "wGQtatJkFMlz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Summary of results\n",
        "- The predictions with noise are close to but not exactly the same as those without noise.\n",
        "- The differences are generally small if the model is reasonably well-behaved and the standard deviation of the noise is low (0.1).\n",
        "- This difference illustrates the effect of input noise and how the model responds to slight variations in input values.\n",
        "- This technique helps in:\n",
        "  - Preventing overfitting by exposing the model to slightly altered data during training.\n",
        "  - Improving generalization to real-world data that may contain natural variability or noise.\n",
        "  - Making the model more robust against adversarial examples or unintended edge-case inputs.\n",
        "  - Enhancing resilience to input fuzzing and injection attacks, which is a valuable defensive measure."
      ],
      "metadata": {
        "id": "xFjUTrbiLAF_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![PART3](https://raw.githubusercontent.com/FSCJ-FacultyDev/HITEC2025/main/images/p3-head.png)\n",
        "# Part 3. Cryptography and Static Analysis\n",
        "1. Implementing Cryptography with Python\n",
        "2. Detecting Vulnerabilities using Static Analysis Tools\n",
        "\n"
      ],
      "metadata": {
        "id": "o_tuaK22v4nB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Implementing Cryptography with Python\n",
        "\n",
        " - # Encryption and Decryption of Sensitive Data\n",
        "\n",
        "- The modern developer's encryption toolbox consists of a modest collection of basic tools.\n",
        "- The following list enumerates the basic crypto security functions and describes what each does, as well as what the security of each depends on:\n",
        "  - **Random numbers** are useful as padding and nonces(*), but only if they are unpredictable.\n",
        "  - **Message digests** (hash functions) serve as a fingerprint of data, but only if impervious to collisions.\n",
        "  - **Symmetric encryption** conceals data based on a secret key the parties share.\n",
        "  - **Asymmetric encryption** conceals data based on a secret the recipient knows.\n",
        "  - **Digital signatures** authenticate data based on a secret only the signer knows.\n",
        "  - **Digital certificates** authenticate signers based on trust in a root certificate.\n",
        "  - **Key exchange** allows two parties to establish a shared secret over an open channel, despite eavesdropping.\n",
        "- [1] Kohnfelder Ch. 5\n",
        "-\\* a **nonce** (short for \"number used once\") is a random value used to ensure that old communications cannot be reused in replay attacks, and to add unpredictability to encryption operations.\n",
        "\n",
        "# 🛠️ Hands-On: Encrypt and Decrypt a Message"
      ],
      "metadata": {
        "id": "0Gtw73fsAy5P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1: Random nonce         — Ensure unpredictable values for operations\n",
        "# 2: Hash message         — Create secure, fixed-size data fingerprint\n",
        "# 3: Symmetric encrypt    — Encrypt with a shared secret\n",
        "# 4: Asymmetric encrypt   — Encrypt with public/private key pairs\n",
        "# 5: Digital signature    — Authenticate sender’s identity and message integrity\n",
        "# 6: Signature verify     — Confirm that signature is authentic\n",
        "# 7: Key exchange         — Establish a new shared secret without prior sharing\n",
        "\n",
        "from cryptography.fernet import Fernet\n",
        "from cryptography.hazmat.primitives import hashes, serialization\n",
        "from cryptography.hazmat.primitives.asymmetric import rsa, padding\n",
        "from cryptography.hazmat.primitives.asymmetric import ec\n",
        "from cryptography.hazmat.primitives.kdf.hkdf import HKDF\n",
        "from cryptography.hazmat.primitives.asymmetric.utils import Prehashed\n",
        "from cryptography.hazmat.backends import default_backend\n",
        "import os\n",
        "import secrets\n",
        "\n",
        "# 1\n",
        "nonce = secrets.token_bytes(16)  # 16-byte random nonce\n",
        "print(\"Random Nonce:\", nonce.hex())\n",
        "\n",
        "# 2\n",
        "message = b\"Confidential data\"\n",
        "digest = hashes.Hash(hashes.SHA256())\n",
        "digest.update(message)\n",
        "message_hash = digest.finalize()\n",
        "print(\"SHA-256 Digest:\", message_hash.hex())\n",
        "\n",
        "# 3\n",
        "symmetric_key = Fernet.generate_key()\n",
        "cipher = Fernet(symmetric_key)\n",
        "\n",
        "encrypted_message = cipher.encrypt(message)\n",
        "print(\"Symmetrically Encrypted Message:\", encrypted_message)\n",
        "\n",
        "decrypted_message = cipher.decrypt(encrypted_message)\n",
        "print(\"Decrypted Symmetric Message:\", decrypted_message.decode())\n",
        "\n",
        "# 4\n",
        "private_key = rsa.generate_private_key(public_exponent=65537, key_size=2048)\n",
        "public_key = private_key.public_key()\n",
        "\n",
        "encrypted_with_public = public_key.encrypt(\n",
        "    message,\n",
        "    padding.OAEP(\n",
        "        mgf=padding.MGF1(algorithm=hashes.SHA256()),\n",
        "        algorithm=hashes.SHA256(),\n",
        "        label=None\n",
        "    )\n",
        ")\n",
        "print(\"Asymmetrically Encrypted Message:\", encrypted_with_public.hex())\n",
        "\n",
        "decrypted_with_private = private_key.decrypt(\n",
        "    encrypted_with_public,\n",
        "    padding.OAEP(\n",
        "        mgf=padding.MGF1(algorithm=hashes.SHA256()),\n",
        "        algorithm=hashes.SHA256(),\n",
        "        label=None\n",
        "    )\n",
        ")\n",
        "print(\"Decrypted Asymmetric Message:\", decrypted_with_private.decode())\n",
        "\n",
        "# 5\n",
        "signature = private_key.sign(\n",
        "    message,\n",
        "    padding.PSS(\n",
        "        mgf=padding.MGF1(hashes.SHA256()),\n",
        "        salt_length=padding.PSS.MAX_LENGTH\n",
        "    ),\n",
        "    hashes.SHA256()\n",
        ")\n",
        "print(\"Digital Signature:\", signature.hex())\n",
        "\n",
        "# 6\n",
        "try:\n",
        "    public_key.verify(\n",
        "        signature,\n",
        "        message,\n",
        "        padding.PSS(\n",
        "            mgf=padding.MGF1(hashes.SHA256()),\n",
        "            salt_length=padding.PSS.MAX_LENGTH\n",
        "        ),\n",
        "        hashes.SHA256()\n",
        "    )\n",
        "    print(\"Signature Verified Successfully!\")\n",
        "except Exception as e:\n",
        "    print(\"Signature Verification Failed:\", e)\n",
        "\n",
        "# skip digital certificates (trust chains)\n",
        "# this would need a real X.509 certificate authority setup (bigger project!)\n",
        "\n",
        "# 7.do key exchange (Elliptic Curve Diffie-Hellman - ECDH)\n",
        "# Simulate two parties generating shared secret\n",
        "\n",
        "# Party A key pair\n",
        "party_a_private_key = ec.generate_private_key(ec.SECP384R1())\n",
        "party_a_public_key = party_a_private_key.public_key()\n",
        "\n",
        "# Party B key pair\n",
        "party_b_private_key = ec.generate_private_key(ec.SECP384R1())\n",
        "party_b_public_key = party_b_private_key.public_key()\n",
        "\n",
        "# Each party computes the shared secret\n",
        "shared_secret_a = party_a_private_key.exchange(ec.ECDH(), party_b_public_key)\n",
        "shared_secret_b = party_b_private_key.exchange(ec.ECDH(), party_a_public_key)\n",
        "\n",
        "# Confirm that both shared secrets match\n",
        "print(\"Shared Secret A:\", shared_secret_a.hex())\n",
        "print(\"Shared Secret B:\", shared_secret_b.hex())\n",
        "print(\"Shared secrets match:\", shared_secret_a == shared_secret_b)\n"
      ],
      "metadata": {
        "id": "QdJklIjaDaPC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Choosing Secure Cryptographic Libraries\n",
        "- Cryptographic libraries are used in software development to securely implement encryption, decryption, authentication, digital signatures, and data integrity checks.\n",
        "  - Selecting the right libraries is critical to building secure applications.\n",
        "  - OWASP provides guidelines for identifying trusted libraries at https://top10proactive.owasp.org/the-top-10/c6-use-secure-dependencies/#implementation  \n",
        "- Python librariy specifics:\n",
        "  1. Use established libraries that are widely trusted and have been subject to external audits, such as **cryptography** (the \"official\" Python cryptography package https://cryptography.io/en/latest/), **PyNaCl** (Python binding to libsodium, a high-level cryptography library), or **PyCryptodome** (a fork of the now-legacy PyCrypto, with active maintenance)\n",
        "  2. Avoid outdated or deprecated libraries like **PyCrypto** (no longer maintained) or custom, hand-rolled cryptography code with potentially unresolved vulnerabilities.\n",
        "  3. Libraries should have a history of frequent updates, security patches, and responsiveness to vulnerability reports.\n",
        "  4. Use simple, high-level cryptographic APIs (like Fernet from cryptography.fernet) instead of directly managing low-level primitives like block ciphers and key scheduling.\n",
        "  5. Verify the library’s license (e.g., Apache 2.0, BSD) fits within your project’s legal and operational requirements.\n",
        "  6. Well-documented libraries with active communities are easier to use securely, reducing the chance of misuse or configuration mistakes."
      ],
      "metadata": {
        "id": "UyiC2e0rkXi2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Secure Hashing and Integrity Checks\n",
        "\n",
        "- Hashing is a cryptographic process that converts data into a fixed-length string (digest), uniquely representing the input.\n",
        "  - Secure hash functions (like SHA-256) are designed to be collision-resistant, fast, and irreversible.\n",
        "  - A hash **collision** is a random match in hash values that occurs when a hashing algorithm produces the same hash value for two distinct pieces of data, e.g.,\n",
        "\n",
        "```\n",
        "hash1\n",
        "         -> 9F86D081884C7D659A2FEAA0C55A...\n",
        "hash2\n",
        "```\n",
        "\n",
        "  - Probability of a collision using SHA256 is = 1 in 2<sup>256</sup> (≈ 1.2 × 1077)\n",
        "  - No efficient algorithm is known to construct sequences with the same hash value\n",
        "  - **Quantum computers** could exploit SHA-256 vulnerabilities by reversing the hashing process\n",
        "- Integrity checks are used to verify that data has not been tampered with or corrupted.\n",
        "  - A newly computed hash of received data can be compared to a previously known good hash.\n",
        "- Any change to the original input (even a single bit) produces a drastically different output.\n",
        "\n",
        "# 🛠️ Hands-On: Verify File Integrity Using SHA-256 Hashing"
      ],
      "metadata": {
        "id": "ErXt3HNXAEiq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import hashlib\n",
        "\n",
        "# create a sample file to hash\n",
        "with open(\"example.txt\", \"w\") as f:\n",
        "    f.write(\"This is some test content for hashing.\\n\")\n",
        "\n",
        "# define the secure hash function\n",
        "def hash_file(filepath):\n",
        "    hasher = hashlib.sha256()\n",
        "    with open(filepath, 'rb') as f:\n",
        "        for chunk in iter(lambda: f.read(4096), b''):\n",
        "            hasher.update(chunk)\n",
        "    return hasher.hexdigest()\n",
        "\n",
        "# hash the file initially\n",
        "original_hash = hash_file(\"example.txt\")\n",
        "\n",
        "# re-hash the file to simulate checking for integrity\n",
        "current_hash = hash_file(\"example.txt\")\n",
        "\n",
        "print(original_hash)\n",
        "print(current_hash)\n",
        "\n",
        "# compare hashes to verify integrity\n",
        "if original_hash == current_hash:\n",
        "    print(\"File integrity verified.\")\n",
        "else:\n",
        "    print(\"File has been altered or corrupted.\")"
      ],
      "metadata": {
        "id": "7MmNZGH0BlD7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Key Management and Storage\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/FSCJ-FacultyDev/HITEC2025/main/images/day3-key.png\">\n",
        "\n",
        "- Managing and storing cryptographic keys securely is just as critical as the algorithms themselves.\n",
        "  - Poor key management can render even the most robust encryption ineffective.\n",
        "- In Python, cryptographic keys may be symmetric (e.g., used with AES) or asymmetric (e.g., public/private RSA or ECC key pairs).\n",
        "- Regardless of the type, keys must be generated using cryptographically secure random number generators (e.g., secrets or os.urandom) and stored in a way that prevents unauthorized access, while still allowing legitimate use within the application.\n",
        "\n",
        "- The cryptography, PyCryptodome, and Fernet libraries described in the \"Choosing Secure Cryptographic Libraries\" section above provide secure ways to generate, serialize, and deserialize keys.\n",
        "  - **cryptography** supports key serialization to PEM or DER formats for both symmetric and asymmetric keys. Private keys can be optionally encrypted with a password during export.\n",
        "  - **PyCryptodome** supports raw and standard formats (e.g., PEM for RSA/ECC). Private keys can be encrypted using passphrases with PKCS#8. Also supports key wrapping for secure key transport and exchange.\n",
        "  - **Fernet** uses fixed-format, URL-safe Base64-encoded 32-byte symmetric keys that are not serialized in PEM/DER formats and are typically stored in secure files or environment variables.\n",
        "- Keys should never be hardcoded in source code or stored in plaintext configuration files; instead, they can be encrypted and stored in environment variables, secure key vaults (like AWS KMS or HashiCorp Vault), or protected OS-specific keyrings.\n",
        "\n",
        "# 🛠️ Hands-On: Manage a Symmetric Encryption Key Using Fernet"
      ],
      "metadata": {
        "id": "_YQ9bHVXLivY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from cryptography.fernet import Fernet\n",
        "\n",
        "# Generate a key and write it to a file\n",
        "key = Fernet.generate_key()\n",
        "with open(\"secret.key\", \"wb\") as key_file:\n",
        "    key_file.write(key)\n",
        "\n",
        "# To use the key later, read it back securely and initialize the cipher object:\n",
        "\n",
        "# Load the key\n",
        "with open(\"secret.key\", \"rb\") as key_file:\n",
        "    key = key_file.read()\n",
        "\n",
        "cipher = Fernet(key)"
      ],
      "metadata": {
        "id": "_Enxi7d9UM6N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Best Practices\n",
        "\n",
        "- Best practices include periodically rotating keys and revoking compromised ones.\n",
        "  - Implementing key rotation involves encrypting data with a new key and optionally decrypting-reencrypting older data, or maintaining a key versioning scheme.\n",
        "  - In a production-grade system, it is often beneficial to separate key management from application logic entirely by delegating to hardware security modules (HSMs) or managed services.\n",
        "  - For local development and learning purposes, securing file permissions and avoiding plaintext exposure are key steps toward better cryptographic hygiene."
      ],
      "metadata": {
        "id": "umK5mbQcW5dA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hardware Security Modules (HSMs)\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/FSCJ-FacultyDev/HITEC2025/main/images/day3-hsm.png\">\n",
        "\n",
        "- HSMs are physical devices designed to protect and manage digital keys and perform cryptographic operations within a tamper-resistant environment.\n",
        "  - AWS CloudHSM (https://aws.amazon.com/cloudhsm) a cloud-based HSM service from Amazon that provides dedicated HSM appliances within AWS infrastructure.\n",
        "  - Azure Dedicated HSM (https://azure.microsoft.com/en-us/products/azure-dedicated-hsm) a managed HSM offering deployed in Azure data centers.\n",
        "  - Google Cloud HSM (https://cloud.google.com/kms/docs/hsm) a cloud-native HSM that integrates with Google Cloud's KMS (see below).\n"
      ],
      "metadata": {
        "id": "uYyvLH68XsTa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Key Management Services\n",
        "- KMS are cloud-based or on-premises services designed to securely create, store, manage, and control access to cryptographic keys, often integrating with applications and infrastructure to simplify encryption and compliance.\n",
        "  - AWS Key Management Service (https://aws.amazon.com/kms/) - integrates with other AWS services and optionally backs keys with AWS CloudHSM.\n",
        "  - Azure Key Vault (https://azure.microsoft.com/en-us/products/key-vault) - a  centralized cloud service for managing keys, secrets, and certificates, optionally backed by HSMs.\n",
        "  - Google Cloud Key Management Service (https://cloud.google.com/security/products/security-key-management) - manages encryption keys for Google Cloud projects with various levels of protection, including Cloud HSM integration.\n",
        "  - HashiCorp Vault (https://www.hashicorp.com/en/products/vault) - a popular open-source and enterprise tool for managing secrets and protecting sensitive data using software-based encryption and optional HSM support (integrated - does not provide it's own HSM)"
      ],
      "metadata": {
        "id": "AxU_v6OBZtuj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Digital Signatures and Authentication\n",
        "\n",
        "- Digital signatures are a cornerstone of modern cryptographic authentication\n",
        "- They provide a way to ensure that a message or document genuinely comes from a trusted source and has not been altered in transit.\n",
        "- Unlike handwritten signatures, which can be forged or copied, digital signatures rely on mathematical algorithms and cryptographic key pairs—specifically asymmetric encryption.\n",
        "- The sender signs a message with their private key, and the recipient verifies the signature using the sender’s public key.\n",
        "- This mechanism guarantees both integrity and authenticity."
      ],
      "metadata": {
        "id": "Omm2js_hckJN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Authentication Using Digital Signatures\n",
        "\n",
        "- Using digital signatures for authentication is common in secure communications protocols such as TLS, S/MIME, and digital certificates in PKI (Public Key Infrastructure).\n",
        "- When a signed message is received, the recipient can verify its origin and confirm that the message content hasn't changed.\n",
        "- This is useful for validating code (e.g., software binaries), securing email, and authenticating identity in blockchain transactions or secure APIs.\n",
        "\n",
        "- In Python, digital signatures can be implemented using libraries like cryptography or PyCryptodome.\n",
        "- Using **cryptography**, you can generate an RSA key pair, sign a message with the private key, and verify the signature with the public key.\n",
        "\n",
        "# 🛠️ Hands-On: Generate RSA Keys, Sign Message, Verify Signature"
      ],
      "metadata": {
        "id": "SlX327aTpQVx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from cryptography.hazmat.primitives.asymmetric import rsa, padding\n",
        "from cryptography.hazmat.primitives import hashes\n",
        "\n",
        "# Generate RSA keys\n",
        "private_key = rsa.generate_private_key(public_exponent=65537, key_size=2048)\n",
        "public_key = private_key.public_key()\n",
        "print(\"RSA key pair generated.\")\n",
        "\n",
        "# Sign a message\n",
        "message = b\"Verify me\"\n",
        "signature = private_key.sign(\n",
        "    message,\n",
        "    padding.PSS(\n",
        "        mgf=padding.MGF1(hashes.SHA256()),\n",
        "        salt_length=padding.PSS.MAX_LENGTH\n",
        "    ),\n",
        "    hashes.SHA256()\n",
        ")\n",
        "print(f\"Message signed: {message.decode()}\")\n",
        "print(f\"Signature (hex): {signature.hex()}\")\n",
        "\n",
        "# Verify the signature\n",
        "try:\n",
        "    public_key.verify(\n",
        "        signature,\n",
        "        message,\n",
        "        padding.PSS(\n",
        "            mgf=padding.MGF1(hashes.SHA256()),\n",
        "            salt_length=padding.PSS.MAX_LENGTH\n",
        "        ),\n",
        "        hashes.SHA256()\n",
        "    )\n",
        "    print(\"Signature is valid. Message is authentic and unchanged.\")\n",
        "except Exception as e:\n",
        "    print(\"Signature verification failed:\", str(e))\n"
      ],
      "metadata": {
        "id": "4GA2hAZPcx8C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## A NOTE on Private Key Generation\n",
        "\n",
        "```\n",
        "private_key = rsa.generate_private_key(public_exponent=65537, key_size=2048)\n",
        "```\n",
        "\n",
        "The arguments **public_exponent** and **key_size** are critical to how the RSA key pair is generated and how secure and efficient it will be.\n",
        "\n",
        "- public_exponent=65537\n",
        "  - This is the RSA public exponent **e**, a value used in the exponentiation step of the encryption. There is also a private exponent **d** which is hidden and calculated from e.\n",
        "  - It must be an odd integer greater than 1.\n",
        "  - 65537 is a widely used standard value because it strikes a balance between security and performance.\n",
        "  - 65537 is prime and has only two bits set (binary: 10000000000000001), making exponentiation efficient.\n",
        "  - Larger values are slower.\n",
        "  - Smaller values have had historical vulnerabilities.\n",
        "- key_size=2048\n",
        "  - This defines the bit length of the RSA modulus, which determines the overall strength of the key.\n",
        "  - A 2048-bit key means the modulus (a large calculated value included in both the public and private keys) is a product of two 1024-bit primes."
      ],
      "metadata": {
        "id": "Qk_s-OefZTuT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Differences between Simple Hashing and RSA Signature Validation\n",
        "| **Feature**     | **Hashing**                                | **Digital Signing with RSA**                                |\n",
        "|-----------------|---------------------------------------------|--------------------------------------------------------------|\n",
        "| **What it does**| Creates a unique fingerprint of data        | Authenticates and proves the origin and integrity of data     |\n",
        "| **Use case**    | Detect changes to data                      | Verify the sender’s identity and detect changes to data       |"
      ],
      "metadata": {
        "id": "82IL1oFVX5x3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using Signatures for Non-Repudiation\n",
        "- **Non-repudiation** is a security principle that ensures a party in a communication cannot deny the authenticity of their signature, message, or action.\n",
        "  - It provides proof of origin and integrity that can be verified by a third party, and is commonly implemented using digital signatures and cryptographic certificates.\n",
        "  - When a user signs a document with their private key, anyone with the corresponding public key can verify that the signature is valid and came from that user.\n",
        "    - Since the private key is known only to the signer, they cannot later claim they didn't sign it—this is the essence of non-repudiation.\n",
        "  - It is widely used in:\n",
        "    - Electronic contracts and legal documents\n",
        "    - Secure email (e.g., with S/MIME or PGP)\n",
        "    - Software distribution to verify trusted sources\n",
        "    - Blockchain transactions to prove ownership or consent\n",
        "  - Beyond simple message authentication, digital signatures are a critical building block for systems that require non-repudiation.\n",
        "  - This ensures that a sender cannot later deny having signed a message, as only their private key could have produced the signature.\n",
        "  - In digital contract systems or electronic voting, non-repudiation is essential to maintain trust and accountability.\n",
        "\n",
        "# 🛠️ Hands-On: Use Non-Repudiation to Verify a Sender"
      ],
      "metadata": {
        "id": "D2Kh7-Zqc0t5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This example simulates a sender signing a message with their private key\n",
        "# and a verifier confirming the signature with the corresponding public key\n",
        "# ==> the sender cannot deny authorship.\n",
        "\n",
        "# Message Integrity: The message has not been tampered with.\n",
        "# Authentication: It came from the holder of the private key.\n",
        "# Non-Repudiation: The signer cannot later deny creating the signature,\n",
        "# because only they had access to the private key.\n",
        "\n",
        "from cryptography.hazmat.primitives import hashes\n",
        "from cryptography.hazmat.primitives.asymmetric import padding, rsa\n",
        "from cryptography.hazmat.primitives import serialization\n",
        "\n",
        "# generate RSA key pair ===\n",
        "private_key = rsa.generate_private_key(public_exponent=65537, key_size=2048)\n",
        "public_key = private_key.public_key()\n",
        "\n",
        "# sender signs the message\n",
        "message = b\"This message is from Alice\"\n",
        "signature = private_key.sign(\n",
        "    message,\n",
        "    padding.PSS(\n",
        "        mgf=padding.MGF1(hashes.SHA256()),\n",
        "        salt_length=padding.PSS.MAX_LENGTH\n",
        "    ),\n",
        "    hashes.SHA256()\n",
        ")\n",
        "\n",
        "# verifier confirms authenticity (non-repudiation)\n",
        "try:\n",
        "    public_key.verify(\n",
        "        signature,\n",
        "        message,\n",
        "        padding.PSS(\n",
        "            mgf=padding.MGF1(hashes.SHA256()),\n",
        "            salt_length=padding.PSS.MAX_LENGTH\n",
        "        ),\n",
        "        hashes.SHA256()\n",
        "    )\n",
        "    print(\"Signature is valid. Message is authentic and unchanged.\")\n",
        "except Exception as e:\n",
        "    print(\"Signature verification failed:\", str(e))"
      ],
      "metadata": {
        "id": "JtzZeD4grsNe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 🛠️ Hands-On: Securing Local File Permissions to Avoiding Plaintext Exposure"
      ],
      "metadata": {
        "id": "LJg2sud-9Yk3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Storing an AES key securely (Linux/macOS)\n",
        "from cryptography.fernet import Fernet\n",
        "import os\n",
        "import stat\n",
        "\n",
        "# Generate a new encryption key\n",
        "key = Fernet.generate_key()\n",
        "\n",
        "# Define a secure file path\n",
        "key_file = \"secret.key\"\n",
        "\n",
        "# Write the key to a file with restricted permissions\n",
        "with open(key_file, \"wb\") as f:\n",
        "    f.write(key)\n",
        "\n",
        "# Set file permission to -rw-------\n",
        "os.chmod(key_file, 0o600)\n",
        "\n",
        "print(\"Key saved securely to\", key_file)\n",
        "file_stat = os.stat(key_file)\n",
        "permissions = stat.filemode(file_stat.st_mode)\n",
        "\n",
        "print(f\"File: {key_file}\")\n",
        "print(f\"Permissions: {permissions}\")"
      ],
      "metadata": {
        "id": "dS52TEYN8O1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Common Pitfalls\n",
        "\n",
        "[\"The highest priority for developers is to build features, and while security is not intentionally on the back burner, they don’t necessarily have the skills to avoid poor coding patterns that lead to security bugs, and the benchmark of a good engineer rarely includes secure coding prowess.\"](https://www.securecodewarrior.com/article/poor-coding-patterns-can-lead-to-big-security-problems-so-why-do-we-encourage-them)  \n",
        "Matias Madou, Ph.D., CTO/Co-Founder, Secure Code Warrior\n",
        "\n",
        "[Common Weakness Enumeration (CWE)](cwe.mitre.org) is a community-developed list of common software and hardware security weaknesses maintained by MITRE Corporation, a nonprofit that operates federally funded research and development centers (FFRDCs) to support U.S. government agencie in cybersecurity and other areas. It helps identify, classify, and mitigate common causes of security vulnerabilities. CVE **tells you what went wrong**; CWE **explains why it was possible**.\n",
        "\n",
        "- Common pitfalls include\n",
        "  - [hardcoding secrets or keys in source code](https://cwe.mitre.org/data/definitions/540.html)\n",
        "  - [using outdated or insecure algorithms](https://cwe.mitre.org/data/definitions/327.html)\n",
        "  - [misusing cryptographic primitives](https://cwe.mitre.org/data/definitions/1240.html)\n",
        "  - [skipping validation or error checking](https://cwe.mitre.org/data/definitions/1215.html)\n",
        "  - [assuming randomness is secure by default](https://cwe.mitre.org/data/definitions/330.html)\n",
        "  - [insecure storage of sensitive files](https://cwe.mitre.org/data/definitions/922.html)"
      ],
      "metadata": {
        "id": "vqOELD6mAlFv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Best Practices\n",
        "\n",
        "- Use high-level abstractions\n",
        "  - High-level libraries like Fernet and cryptography.hazmat.primitives.serialization provide sensible defaults and built-in protections (e.g., encryption with authentication, key serialization standards) so developers don’t have to manage low-level error-prone cryptographic operations.\n",
        "- Leverage environment variables and secrets managers\n",
        "  - Load secrets from os.environ or external vaults (e.g., AWS Secrets Manager, HashiCorp Vault) rather than bundling them with your code.\n",
        "- Validate all inputs before cryptographic operations\n",
        "  - Prevent malformed, tampered, or oversized inputs from causing errors or unexpected behavior. Check the format of incoming public keys or the size of decrypted plaintext.\n",
        "- Always authenticate encrypted data\n",
        "  - Use encryption modes like AES-GCM or tools like Fernet that include built-in authentication to protect both confidentiality and integrity.\n",
        "- Implement key lifecycle management\n",
        "  - Plan for key rotation, expiration, and revocation. Store metadata (e.g., key version, created timestamp) with encrypted content to support future changes.\n",
        "- Handle exceptions gracefully and securely\n",
        "  - Avoid leaking detailed error messages that could help attackers infer internal behavior (e.g., padding oracle attacks). Log minimal information and sanitize outputs.\n",
        "- Test cryptographic logic independently\n",
        "  - Write unit tests specifically for cryptographic operations to verify key generation, encryption-decryption symmetry, and signature validity.\n",
        "- Avoid reinventing protocols\n",
        "  - Resist the temptation to build your own security protocol or tweak standards. Instead, follow established ones like TLS, JOSE (for JWT), or S/MIME."
      ],
      "metadata": {
        "id": "EzRXtW9PAsfU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Detecting Vulnerabilities Using Static Analysis Tools"
      ],
      "metadata": {
        "id": "Vjm78cp-gbrP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Static Code Analysis\n",
        "  - Static analysis is a cornerstone of secure software development, particularly when detecting vulnerabilities early in the development lifecycle.\n",
        "  - Unlike dynamic analysis, which tests programs during execution, static code analysis examines source code or compiled bytecode without executing it.\n",
        "  - This enables detection of syntactic and semantic issues such as buffer overflows, injection flaws, and improper use of APIs before the software is run."
      ],
      "metadata": {
        "id": "2BevhSmG8TkH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Selecting and Implementing Static Analysis Tools\n",
        "  - In Python, tools like pylint, flake8, and bandit are commonly used for static analysis.\n",
        "    - [Bandit](https://github.com/PyCQA/bandit) is designed specifically to find security issues in Python code, such as use of insecure functions or hard-coded passwords.\n"
      ],
      "metadata": {
        "id": "4PFV3f6q8rFt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 🛠️ Hands-On: Use Bandit to Flag vulnerabilities"
      ],
      "metadata": {
        "id": "qc74VHA8PEpR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create a file with a security flaw\n",
        "with open('script.py', 'w') as f:\n",
        "    f.write(\"\"\"\n",
        "# Example Python script with a security flaw\n",
        "import subprocess\n",
        "\n",
        "def ping_server(host):\n",
        "    subprocess.call(f\"ping -c 1 {host}\", shell=True)\n",
        "    # Unsafe: vulnerable to shell injection\n",
        "\"\"\")"
      ],
      "metadata": {
        "id": "NCcNmAE6-Cgl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use bandit to analyze the script file\n",
        "!apt install bandit -y > /dev/null 2>&1 #suppress install output\n",
        "!bandit -r script.py"
      ],
      "metadata": {
        "id": "GgpDJF5l9bNo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "  - The output of Bandit flags the use of subprocess.call with shell=True as a high-severity vulnerability, warning that it may lead to shell injection if the input is not properly sanitized."
      ],
      "metadata": {
        "id": "puDMOE31AsVN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "  - Selecting the right static analysis tool depends on several factors, including the programming language, type of vulnerabilities to detect, integration capabilities with your development environment, and scalability for large codebases.\n",
        "      - Tools like SonarQube, Semgrep, and CodeQL offer cross-language support and can integrate with CI/CD pipelines.\n",
        "      - For Python specifically:\n",
        "        - [Pylint](https://pylint.pycqa.org/) is effective for enforcing coding standards and identifying common logic errors\n",
        "        - [Flake8](https://flake8.pycqa.org/) focuses on style and syntax conformity.\n",
        "        - [Semgrep](https://semgrep.dev/) combines rule-based scanning with fast performance and is particularly useful for finding both security and logic issues."
      ],
      "metadata": {
        "id": "_O-ENlbnKFek"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: running semgrep on a Python file using built-in rules\n",
        "$ semgrep --config=p/ci python_project/"
      ],
      "metadata": {
        "id": "Nfbz4kq5LI5D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- To integrate static analysis tools into your development workflow, they should ideally be part of your IDE and CI/CD pipeline.\n",
        "  - For local development, editors like VS Code and PyCharm support plugins for pylint, flake8, and Bandit, providing real-time feedback.\n",
        "  - In CI/CD environments, GitHub Actions or GitLab CI can be configured to run these tools automatically on each push or pull request, ensuring consistent enforcement of security and style checks."
      ],
      "metadata": {
        "id": "aSh3JnmeLakv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "  - Here is an example of a GitHub Actions workflow that runs bandit on every push.\n",
        "    - We will implement this as a hands-on activity in Part 4\n",
        "\n",
        "```\n",
        "---\n",
        "name: Security Scan\n",
        "\n",
        "on: [push]\n",
        "\n",
        "jobs:\n",
        "  bandit-scan:\n",
        "    runs-on: ubuntu-latest\n",
        "    steps:\n",
        "      - uses: actions/checkout@v2\n",
        "      - name: Set up Python\n",
        "        uses: actions/setup-python@v2\n",
        "        with:\n",
        "          python-version: '3.10'\n",
        "      - name: Install Bandit\n",
        "        run: pip install bandit\n",
        "      - name: Run Bandit\n",
        "        run: bandit -r .\n",
        "```        "
      ],
      "metadata": {
        "id": "SS9gslIgPVFT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Static analysis tools help identify security and quality issues before code reaches production, making them invaluable in modern DevSecOps practices.\n",
        "- Their effectiveness lies not only in the bugs they catch but also in how seamlessly they can be integrated into development and delivery pipelines.\n",
        "- Selecting appropriate tools and incorporating them into both local and automated workflows can significantly reduce the likelihood of shipping insecure or faulty code."
      ],
      "metadata": {
        "id": "k95ozHCsLtnG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Xq7HoKIRlVUM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![PART4](https://raw.githubusercontent.com/FSCJ-FacultyDev/HITEC2025/main/images/p4-head.png)\n",
        "# Part 4. Secure Software Processes\n",
        "1. Threat modeling  \n",
        "2. Secure workflows  \n",
        "3. Automated Security Testing\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "juftpvp4l_mj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Threat Modeling\n",
        "\n",
        "![ThreatZine](https://raw.githubusercontent.com/FSCJ-FacultyDev/HITEC2025/main/images/day4-threatmodeling.png)\n",
        "\n",
        "[7] Shostack Ch. 1\n",
        "- **Threat modeling** is a way to think ahead about security—before your system is built or changed.\n",
        "- Considers system design, components, and data flows to figure out vulnerabilities; ask questions like\n",
        "  - What could go wrong?\n",
        "  - Who might attack this system, and how?\n",
        "  - What damage could they do?\n",
        "  - What can we do to prevent or minimize that damage?\n",
        "- The goal is to spot and fix security issues early, when it is cheaper and easier to do so.\n",
        "- It's a key part of building secure, resilient systems"
      ],
      "metadata": {
        "id": "FTXc73_OQpWz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[1] Kohnfelder Ch. 2\n",
        "- Security mindset means shifting from a builder’s perspective to an attacker’s view\n",
        "- Threats include intentional attacks, accidents, bugs, hardware failures, and human error.\n",
        "- A security mindset helps guide secure decision-making and can be adapted to fit available time and resources.\n",
        "- Incremental improvements in threat identification and mitigation significantly strengthen security even if all vulnerabilities aren't found.\n",
        "  - Can also reveal opportunities for non-security-related improvements e.g., system efficiencies and new features.\n"
      ],
      "metadata": {
        "id": "kJ2laAERnMFk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Identifying Assets and Attack Surfaces\n",
        "- Identify and prioritize software assets based on their value and sensitivity, e.g., applications and APIs (both internal and external), source code and configuration files, data stores (databases, user credentials)\n",
        "- Avoid complex risk calculations; instead, use a simple strategy like the Agile \"T-shirt size\" system (Large, Medium, Small) to prioritize asset protection efforts\n",
        "  - https://www.easyagile.com/blog/agile-estimation-techniques\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "dWVkydPFH_F5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 🛠️ Hands-On: Asset Prioritization using T-Shirt Sizing\n",
        "### Prioritize the Following Assets Using T-Shirt Sizing\n",
        "Match each asset to its appropriate T-shirt size priority:  \n",
        "(Choices: **Extra-Large**, **Large**, **Medium**, **Small**)\n",
        "\n",
        "| Asset | Priority (Match) |\n",
        "|:------------------------|:------------------|\n",
        "| 1. Financial transaction records | ___ |\n",
        "| 2. Internal system logs containing harmless details | ___ |\n",
        "| 3. Customer personal information (e.g., location, identifiers) | ___ |\n",
        "| 4. Client-side application code accessible to all users | ___ |\n",
        "| 5. Private encryption keys used for secure communications | ___ |\n",
        "| 6. Advertising data collected by a social media platform | ___ |\n",
        "\n",
        "<details>\n",
        "<summary>Click to reveal the Answer Key</summary>\n",
        "<br>\n",
        "\n",
        "| Asset | Correct Priority |\n",
        "|:------|:-----------------|\n",
        "| 1. Financial transaction records | Extra-Large |\n",
        "| 2. Internal system logs containing harmless details | Small |\n",
        "| 3. Customer personal information (e.g., location, identifiers) | Large |\n",
        "| 4. Client-side application code accessible to all users | Small |\n",
        "| 5. Private encryption keys used for secure communications | Extra-Large |\n",
        "| 6. Advertising data collected by a social media platform | Medium |\n",
        "</details>\n"
      ],
      "metadata": {
        "id": "68mNe-00Lcwu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Group Similar Assets When Appropriate\n",
        "- Group similar assets when appropriate for easier management, but separate if  risk profiles or usage contexts differ significantly.\n",
        "  - Consider an organization which maintains the following assets:\n",
        "    - Two internal HR web applications hosted on the same internal network.\n",
        "    - A public-facing customer support portal accessible via the internet.\n",
        "    - An internal payroll system that processes sensitive financial data.\n",
        "<details>\n",
        "<summary><strong>How would you group them? (click for suggestions)</strong></summary>\n",
        "<ul>\n",
        "  <li><strong>Group the two internal HR web applications:</strong>\n",
        "    <ul>\n",
        "      <li>Same network.</li>\n",
        "      <li>Accessed by the same group of employees.</li>\n",
        "      <li>Similar security controls and data sensitivity levels.</li>\n",
        "    </ul>\n",
        "  </li>\n",
        "  <li><strong>Do not group the customer support portal with internal applications:</strong>\n",
        "    <ul>\n",
        "      <li>Exposed to the internet and has a larger attack surface.</li>\n",
        "      <li>Subject to different risks, such as DDoS or credential stuffing.</li>\n",
        "      <li>May have a separate set of compliance or logging requirements.</li>\n",
        "    </ul>\n",
        "  </li>\n",
        "  <li><strong>Do not group the payroll system with the HR applications:</strong>\n",
        "    <ul>\n",
        "      <li>Handles more sensitive data (e.g., salaries, bank details).</li>\n",
        "      <li>Requires stricter access controls and different audit requirements.</li>\n",
        "    </ul>\n",
        "  </li>\n",
        "</ul>\n",
        "</details>"
      ],
      "metadata": {
        "id": "taiR-CRTcIc5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Always consider asset value from multiple perspectives — including customers, attackers, and the organization itself — to avoid underestimating potential risks.\n",
        "- Minimize attack surfaces wherever possible, since they are the first points of entry for attackers; early blocking reduces the spread of attacks.\n",
        "- Recognize that attack surfaces include both digital and physical exposures such as public network connections and device interfaces."
      ],
      "metadata": {
        "id": "ybkSb7axQ_ua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using Threat Modeling Frameworks\n",
        "- [5] Olmstead Ch. 6\n",
        "- A **threat modeling framework** provides a structured approach to identifying, evaluating, and addressing potential security threats in a system or application. These frameworks help teams anticipate how attackers might exploit vulnerabilities and guide the design of appropriate defenses before issues occur.\n",
        "- Two common frameworks include **STRIDE** and **DREAD**\n",
        "- The STRIDE model is a Microsoft framework for identifying and categorizing different security threats affecting a system.\n",
        "  - Spoofing - an attacker pretending to be someone/something else, e.g., gaining unauthorized access with a valid user's credentials\n",
        "  - Tampering - unauthorized modification of data, code, or system components, e.g., altering database contents, disrupting a system's regular operation\n",
        "  - Repudiation - denying actions or events by a user or system entity making it hard to attribute responsibility, e.g., manipulating a log file to make it appear someone else did something\n",
        "  - Information disclosure - exposing sensitive information to unauthorized individuals or systems, e.g., sharing confidential data, such as student grade or financial information, or personal health information\n",
        "  - Denial of Service (DOS) - disrupt or degrade the availability of a system or its components, making them inaccessible to legitimate users, e.g., flooding a web server with requests so legitimate users can't access information\n",
        "  - Elevation of privilege - an attacker gains a higher level of access or permission than authorized ones, e.g., a vulnerability allows a user to escalate from regular user to administrator\n",
        "- The DREAD model uses a scale from 0 to 10 for each component, with a lower score being better\n",
        "  - Damage - assesses the potential impact of a security vulnerability if it were to be exploited; 0 indicates no damage, 10 indicates catastrophic damage\n",
        "  - Reproducibility - how easily can an attacker reproduce the conditions necessary to exploit a vulnerability; 0 means the vulnerability is difficult to impossible to reproduce, and 10 means it is effortless to reproduce\n",
        "  - Exploitability - how easily an attacker can exploit a vulnerability, considering the complexity of the attack and skills required to carry it out\n",
        "  - Affected users - assessing the number of users or systems that could be impacted if a vulnerability is exploited\n",
        "  - Discoverability - how easy can a vulnerability be discovered by an attacker; 0 means difficult and 10 means straightforward"
      ],
      "metadata": {
        "id": "P8r-93soCpyy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Threat Modeling tools\n",
        "- [Microsoft Threat Modeling Tool](https://learn.microsoft.com/en-us/azure/security/develop/threat-modeling-tool)\n",
        "- [IBM Gardium Vulnerability Assessment](https://www.ibm.com/products/guardium-vulnerability-assessment)\n",
        "- [OWASP Threat Dragon](https://owasp.org/www-project-threat-dragon/)\n",
        "- [OWASP pytm](https://owasp.org/www-project-pytm/) is a pythonic Framework for threat modeling\n"
      ],
      "metadata": {
        "id": "08mL-qEJTYKJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 🛠️ Hands-On: Use pytm to Create a Threat Model\n",
        "- The following code defines a minimal system architecture with **actors** (entities that interact with the system, such as users or external services), **boundaries** (logical or physical zones that separate trust levels, such as internal networks or the internet), and **dataflows** (paths through which data moves between components, indicating protocols and direction).\n",
        "- The script then generates and renders a threat report using a custom Jinja2 template.\n",
        "- [Jinja2](https://pypi.org/project/Jinja2/) is a Python templating engine that allows dynamic generation of text files (e.g., HTML, Markdown, reports) using placeholders and control structures.\n",
        "  - Templates can include variables, loops, and conditionals, making it easy to separate presentation logic from application logic.\n",
        "  - Commonly used in web development and report generation, Jinja2 integrates seamlessly with tools like Flask, Django, and custom CLI applications like pytm."
      ],
      "metadata": {
        "id": "46f9Qw1R3xDf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytm Jinja2"
      ],
      "metadata": {
        "id": "1KqDYxnGZF3U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile minimal_model.py\n",
        "from pytm import TM, Server, Dataflow, Datastore, Actor, Boundary\n",
        "from jinja2 import Environment, FileSystemLoader\n",
        "import os\n",
        "\n",
        "# STRIDE category inference is used below because built-in pytm threats\n",
        "# often lack an explicit category. Keyword matching is used to approximate\n",
        "# for reporting purposes. Some threats may still be unlabeled.\n",
        "\n",
        "STRIDE_CATEGORIES = {\n",
        "    # Spoofing\n",
        "    \"spoof\": \"Spoofing\",\n",
        "    \"forging\": \"Spoofing\",\n",
        "    \"impersonation\": \"Spoofing\",\n",
        "    \"credential falsification\": \"Spoofing\",\n",
        "    \"session hijacking\": \"Spoofing\",\n",
        "    \"replay\": \"Spoofing\",\n",
        "\n",
        "    # Tampering\n",
        "    \"tamper\": \"Tampering\",\n",
        "    \"manipulation\": \"Tampering\",\n",
        "    \"injection\": \"Tampering\",\n",
        "    \"sql\": \"Tampering\",\n",
        "    \"command\": \"Tampering\",\n",
        "    \"format string\": \"Tampering\",\n",
        "    \"api manipulation\": \"Tampering\",\n",
        "    \"overwriting\": \"Tampering\",\n",
        "    \"overwrite\": \"Tampering\",\n",
        "\n",
        "    # Repudiation\n",
        "    \"repudiation\": \"Repudiation\",\n",
        "    \"audit log manipulation\": \"Repudiation\",\n",
        "    \"log tampering\": \"Repudiation\",\n",
        "\n",
        "    # Information Disclosure\n",
        "    \"leak\": \"Information Disclosure\",\n",
        "    \"exfiltration\": \"Information Disclosure\",\n",
        "    \"exposure\": \"Information Disclosure\",\n",
        "    \"unprotected\": \"Information Disclosure\",\n",
        "    \"disclosure\": \"Information Disclosure\",\n",
        "    \"data leak\": \"Information Disclosure\",\n",
        "    \"sensitive\": \"Information Disclosure\",\n",
        "    \"sniffing\": \"Information Disclosure\",\n",
        "\n",
        "    # Denial of Service\n",
        "    \"flood\": \"Denial of Service\",\n",
        "    \"dos\": \"Denial of Service\",\n",
        "    \"denial\": \"Denial of Service\",\n",
        "    \"overflow\": \"Denial of Service\",\n",
        "    \"crash\": \"Denial of Service\",\n",
        "    \"allocation\": \"Denial of Service\",\n",
        "    \"ping of the death\": \"Denial of Service\",\n",
        "    \"smuggling\": \"Denial of Service\",\n",
        "    \"excessive\": \"Denial of Service\",\n",
        "\n",
        "    # Elevation of Privilege\n",
        "    \"privilege\": \"Elevation of Privilege\",\n",
        "    \"escalation\": \"Elevation of Privilege\",\n",
        "    \"bypass\": \"Elevation of Privilege\",\n",
        "    \"unauthorized\": \"Elevation of Privilege\",\n",
        "    \"elevation\": \"Elevation of Privilege\",\n",
        "    \"root\": \"Elevation of Privilege\",\n",
        "    \"admin\": \"Elevation of Privilege\",\n",
        "}\n",
        "\n",
        "def infer_stride_category(threat):\n",
        "    description = threat.description.lower()\n",
        "    name = threat.__class__.__name__.lower()\n",
        "\n",
        "    for keyword, stride in STRIDE_CATEGORIES.items():\n",
        "        if keyword in description or keyword in name:\n",
        "            return stride\n",
        "    return \"Uncategorized\"\n",
        "\n",
        "  # Create a new threat model instance\n",
        "tm = TM(\"Minimal Threat Model\")\n",
        "\n",
        "# define a basic system architecture\n",
        "\n",
        "# trust boundaries\n",
        "internet = Boundary(\"Internet\")\n",
        "internal = Boundary(\"Internal Network\")\n",
        "\n",
        "# external actor\n",
        "user = Actor(\"User\")\n",
        "\n",
        "# key components\n",
        "web_server = Server(\"Web Server\", boundary=internet)\n",
        "db = Datastore(\"Database\", boundary=internal)\n",
        "\n",
        "# data flows\n",
        "Dataflow(user, web_server, \"User sends credentials\", protocol=\"HTTPS\")\n",
        "Dataflow(web_server, db, \"Web server queries user info\", protocol=\"SQL\")\n",
        "\n",
        "# Process the model to populate threats\n",
        "tm.process()\n",
        "\n",
        "# Access the elements\n",
        "all_elements = list(tm._elements)\n",
        "dataflows = [e for e in all_elements if isinstance(e, Dataflow)]\n",
        "components = [e for e in all_elements if not isinstance(e, Dataflow)]\n",
        "threats = list(tm._threats)\n",
        "\n",
        "# Infer STRIDE category for each threat\n",
        "for threat in threats:\n",
        "    threat.category = infer_stride_category(threat)\n",
        "\n",
        "# Set up Jinja2 templating\n",
        "env = Environment(loader=FileSystemLoader(searchpath=os.path.dirname(__file__)))\n",
        "template = env.get_template(\"custom_report.jinja2\")\n",
        "output = template.render(tm=tm, elements=components, dataflows=dataflows, threats=threats)\n",
        "\n",
        "print(output)\n",
        "\n"
      ],
      "metadata": {
        "id": "3nazbuP9ZMey"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile custom_report.jinja2\n",
        "{# create custom template #}\n",
        "Threat Model: {{ tm.name }}\n",
        "=========================\n",
        "\n",
        "Components:\n",
        "{% for element in elements %}\n",
        "- {{ element.name }} ({{ element.__class__.__name__ }})\n",
        "{% endfor %}\n",
        "\n",
        "Data Flows:\n",
        "{% for df in dataflows %}\n",
        "- {{ df.name }}: {{ df.source.name }} → {{ df.sink.name }} via {{ df.protocol }}\n",
        "{% endfor %}\n",
        "\n",
        "Threats:\n",
        "Threats:\n",
        "{% for threat in threats %}\n",
        "- **{{ threat.target.name if threat.target else \"General Threat\" }}**:\n",
        "  - **Type:** {{ threat.__class__.__name__.replace('_', ' ') }}\n",
        "  - **STRIDE:** {{ threat.category if threat.category else \"Uncategorized\" }}\n",
        "  - **Description:** {{ threat.description }}\n",
        "{% endfor %}\n"
      ],
      "metadata": {
        "id": "ylE8Xu-Yx7fe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The threat list covers common attack types like injection, spoofing, and\n",
        "# session hijacking, as identified by pytm's built-in threat modeling logic.\n",
        "!python3 minimal_model.py"
      ],
      "metadata": {
        "id": "itchAQNVyK78"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Secure Workflows\n"
      ],
      "metadata": {
        "id": "xvX6-2AOhVJB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Secure Development Workflows\n",
        "- A **Secure Development Workflow** integrates security practices throughout the entire software development lifecycle, from initial planning to deployment and maintenance.\n",
        "- These workflows ensure that security is not treated as an afterthought, but as a core component of every phase of development.\n",
        "- Key practices include threat modeling during design, secure coding standards during implementation, static and dynamic analysis during testing, and secure configuration management during deployment.\n",
        "- Secure workflows also emphasize the use of version control, peer reviews, and automated CI/CD pipelines to reduce the risk of introducing vulnerabilities and to detect issues early.\n"
      ],
      "metadata": {
        "id": "ju3vHTULXVDQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Integration in the SDLC\n",
        "![SecureAgile](https://raw.githubusercontent.com/FSCJ-FacultyDev/HITEC2025/main/images/day4-secureagilesdlc.png)\n",
        "- By embedding security controls directly into development processes, teams can more effectively manage risks without slowing down delivery.\n",
        "- Secure development workflows promote collaboration between developers, security professionals, and operations teams, following methodologies such as DevSecOps.\n",
        "- These workflows often include automated tools for code scanning, dependency checking, and infrastructure validation, allowing security to scale with development **velocity** (the speed and efficiency of delivering code changes to production).\n",
        "- Secure development workflows lead to more resilient applications, reduced remediation costs, and greater compliance with regulatory and industry standards."
      ],
      "metadata": {
        "id": "ntkNKOG7Yndm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Integrating Security into CI/CD Pipelines\n",
        "- **CI/CD** (Continuous Integration and Continuous Deployment) refers to the practice of regularly merging code changes with automated builds and tests to catch issues early (CI) and automatically releasing validated changes to production or staging environments (CD).\n",
        "- Integrating automated security tests into CI/CD pipeline ensures that vulnerabilities are detected and addressed early—during code commits, builds, and deployments, rather than after release.\n",
        "- Common integrations include static application security testing (SAST), dependency scanning, secret detection, and configuration validation tools that run automatically as part of the pipeline.\n",
        "- By **shifting security left** and making it a routine part of development workflows, teams can reduce risk without compromising development velocity and maintain a consistent security baseline across all code changes.  \n",
        "![ShiftLeft](https://raw.githubusercontent.com/FSCJ-FacultyDev/HITEC2025/main/images/day4-devsecshiftleft.png)\n",
        "- As a practical example, developers can integrate tools like Bandit into their GitHub CI workflows to automatically detect common Python security issues during each code push."
      ],
      "metadata": {
        "id": "bQQ9pL7OY2gY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 🛠️ Hands-On: Integrate Bandit into a GitHub Actions Workflow\n",
        "\n",
        "- In this hands-on we will add a GitHub workflow to our python-demo-project repository from Part 1 to demonstrate a secure development workflow into our project.\n",
        "\n",
        "1. Add the following file to your repository as **.github/workflows/bandit.yml**\n",
        "---\n",
        "\n",
        "```\n",
        "name: Security Scan\n",
        "\n",
        "on: [push]\n",
        "\n",
        "jobs:\n",
        "  bandit-scan:\n",
        "    runs-on: ubuntu-latest\n",
        "    steps:\n",
        "      - uses: actions/checkout@v2\n",
        "      - name: Set up Python\n",
        "        uses: actions/setup-python@v2\n",
        "        with:\n",
        "          python-version: '3.10'\n",
        "      - name: Install Bandit\n",
        "        run: pip install bandit\n",
        "      - name: Run Bandit\n",
        "        run: bandit -r .\n",
        "```\n",
        "\n",
        "- After committing the file, click on the \"Actions\" menu from your repository's home page.\n",
        "- Bandit is configured to return a non-zero status for any vulnerabilities found, even those with moderate severity.\n",
        "- Our initial Python code made a call to **requests.get** with no timeout, which is viewed as a moderate vulnerability.\n",
        "- We can modify the execution to supress the lower sev issues as follows:\n",
        "\n",
        "```\n",
        "    bandit -r . --severity-level high\n",
        "```\n",
        "  - or we can fix the problem; add a timeout to the call.\n",
        "  - This is a good way to retest our action and verify our security test passes; the script will run when we commit the following change:\n",
        "\n",
        "- Edit the main.py file and change\n",
        "\n",
        "```\n",
        "    response = requests.get(\"https://www.example.com\")\n",
        "```\n",
        "- to\n",
        "\n",
        "```\n",
        "    response = requests.get(\"https://www.example.com\", timeout=5)\n",
        "```\n",
        "\n",
        "- then commit your change and view the Actions results again (it may be in a pending status for awhile, since we use free GitHub we aren't usually first in line)."
      ],
      "metadata": {
        "id": "HBevPhBTbDSc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Secure Design Reviews and Approval Processes\n",
        "![CodeReview](https://raw.githubusercontent.com/FSCJ-FacultyDev/HITEC2025/main/images/day4-codereviews.png)\n",
        "- Vulnerabilities and insecure code should be identified before deployment.\n",
        "- This requires systematic inspection of source code by one or more qualified reviewers looking for issues such as\n",
        "  - improper input validation\n",
        "  - insecure cryptographic use\n",
        "  - injection flaws\n",
        "  - logic errors\n",
        "- Code reviews not only help find bugs but also encourage developers to follow\n",
        " secure coding standards and best practices (e.g., [OWASP](https://owasp.org/www-project-top-ten/) and [CERT](https://wiki.sei.cmu.edu/confluence/display/seccode/SEI+CERT+Coding+Standards)).\n",
        " - OWASP Guidelines for code reviews can be found [here](https://owasp.org/www-project-code-review-guide/assets/OWASP_Code_Review_Guide_v2.pdf)."
      ],
      "metadata": {
        "id": "n2vAv00-kqJu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Effective Security Design Reviews\n",
        "- References\n",
        "- [Microsoft](https://www.microsoft.com/en-us/securityengineering/sdl/practices)\n",
        "- [OWASP](https://owasp.org/www-project-application-security-verification-standard/)\n",
        "- [NIST](https://csrc.nist.gov/publications/detail/sp/800-218/final)\n",
        "- [GitHub](https://github.com/google/eng-practices/blob/master/review/index.md)\n",
        "- An effective secure review combines manual inspection with automated tools\n",
        "  - Manual reviews allow human reviewers to spot complex logic flaws and subtle security issues that scanners might miss\n",
        "  - Automated static analysis tools can efficiently catch repetitive patterns, outdated libraries, or known vulnerabilities across large codebases.\n",
        "    - Integrating these tools into a CI/CD pipeline ensures that each pull request or code commit is scanned early, preventing security regressions and helping teams maintain a strong security posture throughout the development cycle."
      ],
      "metadata": {
        "id": "3MmElW67mzRb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Secure Design Review Checklist\n",
        "  1. Understand the System Context\n",
        "    - Have all components, data flows, and trust boundaries been identified?\n",
        "    - Has a threat model (e.g., STRIDE or DREAD) been developed for the system?\n",
        "    - Are all third-party services, libraries, and APIs documented?\n",
        "  2. Authentication & Authorization\n",
        "    - Does the system enforce strong, secure user authentication?\n",
        "    - Are authentication credentials securely stored (e.g., hashed and salted passwords)?\n",
        "    - Is access control enforced at all critical entry points?\n",
        "    - Are role-based or attribute-based access control models clearly defined?\n",
        "  3. Data Protection & Privacy\n",
        "    - Is sensitive data (PII, credentials, tokens) encrypted in transit (TLS) and at rest?\n",
        "    - Are proper cryptographic algorithms and key lengths selected?\n",
        "    - Is key management handled securely and separately from application logic?\n",
        "    - Are data retention and deletion policies aligned with privacy requirements?\n",
        "  4. Input Validation & Output Encoding\n",
        "    - Is all user input validated, sanitized, and length-limited?\n",
        "    - Are appropriate output encoding mechanisms in place to prevent injection attacks (e.g., XSS, SQLi)?\n",
        "    - Are dangerous file uploads, redirects, or deserialization scenarios accounted for?\n",
        "  5. Error Handling & Logging\n",
        "    - Are errors logged in a secure, centralized location without exposing sensitive details?\n",
        "    - Do error messages avoid revealing internal implementation details to users?\n",
        "    - Are logs protected from tampering and accessible only to authorized users?\n",
        "  6. Secure Communications\n",
        "    - Is TLS enforced for all client-server and service-to-service communication?\n",
        "    - Are certificates validated, and is certificate pinning considered for critical systems?\n",
        "    - Are insecure protocols (e.g., HTTP, FTP) avoided?\n",
        "  7. Dependency & Environment Security\n",
        "    - Are third-party libraries and dependencies tracked and regularly scanned for vulnerabilities (e.g., via SBOM or SCA tools)?\n",
        "    - Is the build and deployment environment hardened against supply chain attacks?\n",
        "    - Are secrets managed securely (e.g., not hardcoded or in source control)?\n",
        "  8. Secure Defaults & Fail-Safe Design\n",
        "    - Does the system follow the principle of least privilege by default?\n",
        "    - Are security controls opt-out rather than opt-in?\n",
        "    - Does the system fail securely (e.g., deny access by default when uncertain)?\n",
        "  9. Resilience & Threat Mitigation\n",
        "    - Are rate limiting, CAPTCHA, or other bot defenses implemented where needed?\n",
        "    - Is the system protected against common attacks (e.g., replay attacks, CSRF, DoS)?\n",
        "    - Are security headers (e.g., CSP, HSTS, X-Frame-Options) considered for web apps?\n",
        "  10. Review & Documentation\n",
        "    - Has the design been reviewed by at least one independent security reviewer?\n",
        "    - Are security assumptions, decisions, and mitigations documented?\n",
        "    - Are plans in place for ongoing threat monitoring and incident response?"
      ],
      "metadata": {
        "id": "6Euk2I9D9OLM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Approval processes further reinforce security by requiring that code cannot be merged into the main branch without passing defined **security gates**.\n",
        "- These gates include\n",
        "  - successful automated tests\n",
        "  - static analysis results\n",
        "  - formal sign-off from security-trained reviewers.\n",
        "\n",
        "- Role-based access control (RBAC) within source control systems ensures that only authorized individuals can approve or deploy changes.\n",
        "- Since a merge can be blocked when a security gate failure occurs, feedback should always be provided which helps the developer(s) resolve the issue(s) and learn from the experience."
      ],
      "metadata": {
        "id": "R27CtIUcnOdQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Incident Response\n",
        "- Operational processes must be able to withstand, respond to, and recover from security incidents without compromising data integrity or business continuity\n",
        "- Secure workflows are designed not only to prevent unauthorized actions but also to remain resilient under attack or failure.\n",
        "- By integrating incident response into the lifecycle, organizations ensure that even if a breach or disruption occurs, there are predefined procedures in place to contain the threat, minimize impact, and restore secure operations.\n",
        "- This reinforces both trust and continuity in systems that handle sensitive or mission-critical activities."
      ],
      "metadata": {
        "id": "w_IwCXumxWbV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Workflow Recovery\n",
        "- Following an incident, workflow recovery is integral to restoring affected business functions and digital services following an incident.\n",
        "- This includes the recovery of applications, user access, and dependent systems in accordance with defined recovery time objectives (RTOs) and recovery point objectives (RPOs).\n",
        "- Workflow recovery plans may involve failover systems, backups, and automated deployment scripts to rebuild environments efficiently.\n",
        "- Coordination between IT, development, and security teams is essential to ensure continuity and reduce downtime.\n",
        "- Integrating workflow recovery with incident response ensures not only that threats are neutralized, but that services are brought back online in a secure and controlled manner."
      ],
      "metadata": {
        "id": "RGt_MDagMaZz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Automating Security Testing\n",
        "- Integrating automated security tests into CI/CD Pipelines ensures that vulnerabilities are caught early in the development lifecycle, reducing the risk of deploying insecure code.\n",
        "- Using automated tools for static application security testing (SAST), dependency scanning, and secret detection within build and deployment workflows helps enforce security policies without delaying delivery.\n",
        "- This also helps developers receive immediate feedback when insecure code or libraries are introduced, allowing issues to be resolved before reaching production.\n",
        "- Security gates in CI/CD pipelines can also be configured to block deployments if critical findings are detected, reinforcing a shift-left security strategy."
      ],
      "metadata": {
        "id": "JVJGEWNyhiZ4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Security Test Coverage and Prioritization\n",
        "- The most critical parts of an application (such as authentication logic, data processing, and external interfaces) must be thoroughly tested for vulnerabilities.\n",
        "- Since testing every line of code equally is often impractical, prioritization helps focus security efforts on high-risk areas that handle sensitive data or have a history of exploitation.\n",
        "- Effective coverage (the extent to which your security tests examine critical code paths, inputs, and features) includes a mix of static and dynamic analysis, dependency checks, and manual reviews for complex logic.\n",
        "- Mapping tests to known threat models or CWE categories can help guide where deeper scrutiny is needed, making security testing more efficient and impactful across the development lifecycle."
      ],
      "metadata": {
        "id": "PYTadqcvhUQB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Managing False Positives\n",
        "- False positives in security test findings must be managed to distinguish real vulnerabilities from incorrect alerts.\n",
        "- This is essential to maintaining trust in automated security tools and avoiding wasted developer effort.\n",
        "- When tools produce too many irrelevant warnings, teams may start ignoring results altogether, missing real threats in the process.\n",
        "- Prioritizing findings based on severity, exploitability, and impact helps filter meaningful issues from noise.\n",
        "- Integrating results into developer workflows with clear remediation guidance also improves response time and reduces frustration.\n",
        "- Regular tuning of security tools and rulesets is necessary to adapt to evolving codebases and reduce alert fatigue.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "dDbf7AaniCBb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prioritizing Findings\n",
        "- By considering not just severity but also **exploitability** (how easy it is to take advantage of the issue) and **impact** (what harm it can cause), developers can focus on what truly needs immediate action and avoid wasting time on theoretical or low-risk findings.\n",
        "## Examples\n",
        "### CVE-2022-12345 – SQL Injection in Login Endpoint\n",
        "Severity: High  \n",
        "Exploitability: Easy (public exploit available)  \n",
        "Impact: Allows account takeover  \n",
        "Priority: Critical — Fix Immediately\n",
        "### Hardcoded test credentials found in test_config.py\n",
        "Severity: Medium  \n",
        "Exploitability: Low (file not deployed in production)  \n",
        "Impact: No direct production risk  \n",
        "Priority: Low — Address later or exclude from scan scope\n",
        "### Outdated jQuery version detected\n",
        "Severity: Medium  \n",
        "Exploitability: Medium (theoretical exploit)  \n",
        "Impact: Potential XSS on legacy admin tools  \n",
        "Priority: Medium — Plan patch in next sprint  \n",
        "### Missing HttpOnly flag on session cookie\n",
        "Severity: High  \n",
        "Exploitability: Moderate  \n",
        "Impact: Increases XSS impact  \n",
        "Priority: High — Patch in current release\n",
        "### Unused dependency xmltodict with known DoS vulnerability\n",
        "Severity: High  \n",
        "Exploitability: Low (not imported anywhere)  \n",
        "Impact: Minimal unless activated  \n",
        "Priority: Low — Remove when cleaning dependencies"
      ],
      "metadata": {
        "id": "gCVW2LsliqQl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SBOMs\n",
        "- A Software Bill of Materials (SBOM) is a detailed inventory of all components, libraries, and dependencies used by a software application.  \n",
        "- It provides a comprehensive record which lists open-source, proprietary, and third-party components.  \n",
        "- It contains component metadata, including version numbers, licenses, and source information.  \n",
        "- SBOMs promote visibility into the software supply chain and are used in conjunction with scanning tools to identify components with known security issues\n",
        "- Popular SBOM generators include [Trivy](https://trivy.dev/latest/), [CycloneDX](https://cyclonedx.org/), [SPDX](https://spdx.dev/), [OWASP Dependency-Track](https://dependencytrack.org/), [Syft](https://www.cisa.gov/resources-tools/services/syft), [Anchore](https://anchore.com/), and [FOSSA](https://fossa.com/).\n",
        "- SBOM scans are typically run as part of automated CI/CD workflows to verify:\n",
        "  - Known vulnerabilities in dependencies\n",
        "  - License compliance and component provenance\n",
        "  - Tampering or unauthorized components in build artifacts\n",
        "- SBOM data is cross-referenced with vulnerability databases (e.g., CVE, National Vulnerability Database, Aqua Vulnerability Database, OSS Index, GitHub Advisory Database, Snyk Vulnerability Database) to identify known issues\n",
        "- Languages other than Python are also vulnerable, e.g. JavaScript/Node.js (npm), Java (Maven Central), and others\n",
        "\n"
      ],
      "metadata": {
        "id": "71Wy7OADjfH9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 🛠️ Hands-On: Run an SBOM check"
      ],
      "metadata": {
        "id": "jK7e-I0HlAQx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip freeze >requirements.txt\n",
        "!echo 'showing line count for dependencies:'\n",
        "!wc -l requirements.txt"
      ],
      "metadata": {
        "id": "bkadn8u5bhC1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get install wget apt-transport-https gnupg lsb-release\n",
        "!wget -qO - https://aquasecurity.github.io/trivy-repo/deb/public.key | sudo apt-key add -\n",
        "!echo deb https://aquasecurity.github.io/trivy-repo/deb $(lsb_release -sc) main | sudo tee -a /etc/apt/sources.list.d/trivy.list\n",
        "!sudo apt-get update\n",
        "!sudo apt-get install trivy"
      ],
      "metadata": {
        "id": "B1vmBeBNlT3d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install cyclonedx-bom\n",
        "!python3 -m cyclonedx_py requirements -i requirements.txt -o sbom.json\n",
        "!trivy sbom sbom.json"
      ],
      "metadata": {
        "id": "TXmijoi3c227"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Results\n",
        "- Environment scanned: Python packages (via SBOM from requirements.txt)\n",
        "- Total Vulnerabilities Found: 10\n",
        "  - High severity: 5\n",
        "  - Medium: 3\n",
        "  - Low: 2\n",
        "  - Critical: 0\n",
        "- Warnings: Trivy warns that SBOMs generated by third-party tools (like cyclonedx-bom) may lead to incomplete or imprecise matching, but this report still picked up valid CVEs based on package name and version, so the findings are informative and should not be ignored.\n",
        "- Each row in the table tells you:\n",
        "  - Library: The affected package\n",
        "  - Vulnerability: CVE ID with severity (e.g. CVE-2022-40023)\n",
        "  - Installed Version: The version in your Colab environment\n",
        "  - Fixed Version: The version where the issue is patched\n",
        "  - Title + Link: A brief vulnerability description and a link for more info\n",
        "- Examples:\n",
        "  - High Severity\n",
        "    - Mako 1.1.3 → vulnerable to CVE-2022-40023 (Regular Expression DoS)\n",
        "      - Fixed in 1.2.2\n",
        "    - keras 3.8.0 → vulnerable to CVE-2025-1550\n",
        "      - Fixed in 3.9.0\n",
        "    - jupyter-server has multiple high and medium CVEs\n",
        "  - cryptography 43.0.3 has a known LOW severity issue — fixed in 44.0.1\n",
        "- Should You Be Concerned?\n",
        "  - Yes, especially for HIGH severity vulnerabilities in actively used libraries like keras (RCE risk), jupyter-server (user hash disclosure, redirection, etc.), and Mako (REDos).\n",
        "  - These could impact the confidentiality, integrity, or availability of systems if exposed to malicious input — particularly in multi-user/shared environments like Jupyter notebooks or APIs.\n",
        "- What You Should Do\n",
        "  - Upgrade the packages: use pip install --upgrade <package> or pin higher versions in requirements.txt\n",
        "  - Avoid vulnerable versions when building distributable apps or APIs."
      ],
      "metadata": {
        "id": "XTtW55QRgcgC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Integrating a Scan into a GitHub Action\n",
        "### Sample YAML file; store in .github/workflows\n",
        "\n",
        "```\n",
        "name: Trivy Dependency Scan\n",
        "\n",
        "on:\n",
        "  push:\n",
        "    branches: [ \"main\" ]\n",
        "  pull_request:\n",
        "    branches: [ \"main\" ]\n",
        "\n",
        "jobs:\n",
        "  trivy-scan:\n",
        "    name: Scan Python dependencies with Trivy\n",
        "    runs-on: ubuntu-latest\n",
        "\n",
        "    steps:\n",
        "      - name: Checkout repository\n",
        "        uses: actions/checkout@v3\n",
        "\n",
        "      - name: Install Trivy\n",
        "        run: |\n",
        "          sudo apt-get update\n",
        "          sudo apt-get install -y wget\n",
        "          wget https://github.com/aquasecurity/trivy/releases/latest/download/trivy_0.48.4_Linux-64bit.deb\n",
        "          sudo dpkg -i trivy_0.48.4_Linux-64bit.deb\n",
        "\n",
        "      - name: Scan project directory for vulnerabilities\n",
        "        run: trivy fs --exit-code 1 --severity CRITICAL,HIGH .\n",
        "\n",
        "      # Optional: Save Trivy scan report as an artifact\n",
        "      - name: Save Trivy scan report\n",
        "        run: trivy fs --severity CRITICAL,HIGH --format table --output trivy-report.txt .\n",
        "      \n",
        "      - name: Upload report\n",
        "        uses: actions/upload-artifact@v3\n",
        "        with:\n",
        "          name: trivy-report\n",
        "          path: trivy-report.txt\n",
        "```"
      ],
      "metadata": {
        "id": "PSIa7NKzo1My"
      }
    }
  ]
}